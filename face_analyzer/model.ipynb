{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 별 x, y 좌표 추출\n",
    "def extract_coordinates(dataframe):\n",
    "    coordinates = {}\n",
    "    for image_name in dataframe['image_name'].unique():\n",
    "        # 해당 이미지의 데이터 필터링\n",
    "        image_data = dataframe[dataframe['image_name'] == image_name]\n",
    "        # x, y 좌표 배열 생성\n",
    "        x_coords = image_data['x'].tolist()\n",
    "        y_coords = image_data['y'].tolist()\n",
    "        # 딕셔너리에 저장\n",
    "        coordinates[image_name] = {'x': x_coords, 'y': y_coords}\n",
    "    return coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "neutral_df = pd.read_csv(\"../output/neutral.csv\")\n",
    "angry_df = pd.read_csv(\"../output/angry.csv\")\n",
    "happy_df = pd.read_csv(\"../output/happy.csv\")\n",
    "neutral_df['label'] = 0\n",
    "happy_df['label'] = 1\n",
    "angry_df['label'] = 2\n",
    "\n",
    "face_metadata_df = pd.concat([neutral_df, angry_df, happy_df], ignore_index=True)\n",
    "face_metadata_df = face_metadata_df.sort_values(by=\"image_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>face_id</th>\n",
       "      <th>point_id</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C0000.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>152</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>C0000.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>159</td>\n",
       "      <td>103</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>C0000.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>161</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>C0000.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>165</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>C0000.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>169</td>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_name  face_id  point_id    x    y  label\n",
       "0   C0000.jpg        0         0  152  106      0\n",
       "36  C0000.jpg        0        36  159  103      0\n",
       "37  C0000.jpg        0        37  161  101      0\n",
       "38  C0000.jpg        0        38  165  101      0\n",
       "39  C0000.jpg        0        39  169  104      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_metadata_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_face_metadata_df = face_metadata_df.drop('label', axis=1)\n",
    "y_face_metadata_df = face_metadata_df[['image_name', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>face_id</th>\n",
       "      <th>point_id</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C0000.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>152</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>C0000.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>159</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>C0000.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>161</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>C0000.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>165</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>C0000.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>169</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_name  face_id  point_id    x    y\n",
       "0   C0000.jpg        0         0  152  106\n",
       "36  C0000.jpg        0        36  159  103\n",
       "37  C0000.jpg        0        37  161  101\n",
       "38  C0000.jpg        0        38  165  101\n",
       "39  C0000.jpg        0        39  169  104"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_face_metadata_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C0000.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>C0000.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>C0000.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>C0000.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>C0000.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_name  label\n",
       "0   C0000.jpg      0\n",
       "36  C0000.jpg      0\n",
       "37  C0000.jpg      0\n",
       "38  C0000.jpg      0\n",
       "39  C0000.jpg      0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_face_metadata_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def convert_to_X_train(target_df: pd.DataFrame) -> np.ndarray:\n",
    "    return np.array([\n",
    "        group[[\"x\", \"y\"]].values\n",
    "        for _, group in target_df.groupby(\"image_name\")\n",
    "    ])\n",
    "    \n",
    "x_train_data = convert_to_X_train(x_face_metadata_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_Y_train(target_df: pd.DataFrame):\n",
    "    result = target_df.drop_duplicates('image_name').copy()\n",
    "    result['neutral'] = result['label'].map({ 0: 1, 1: 0, 2: 0})\n",
    "    result['happy'] = result['label'].map({ 0: 0, 1: 1, 2: 0 })\n",
    "    result['angry'] = result['label'].map({ 0: 0, 1: 0, 2: 1 })                                           \n",
    "    \n",
    "    return np.array(result.drop(['image_name', 'label'], axis=1))\n",
    "\n",
    "y_train_data = convert_to_Y_train(y_face_metadata_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(x_train_data,\n",
    "                                                    y_train_data,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66664\n",
      "66664\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape[0])\n",
    "print(Y_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflowNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading tensorflow-2.18.0-cp311-cp311-win_amd64.whl.metadata (3.3 kB)\n",
      "Collecting tensorflow-intel==2.18.0 (from tensorflow)\n",
      "  Downloading tensorflow_intel-2.18.0-cp311-cp311-win_amd64.whl.metadata (4.9 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\kevin\\anaconda3\\envs\\facedetect\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.2)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading protobuf-5.29.1-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Collecting requests<3,>=2.21.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\kevin\\anaconda3\\envs\\facedetect\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\kevin\\anaconda3\\envs\\facedetect\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\kevin\\anaconda3\\envs\\facedetect\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.12.2)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading wrapt-1.17.0-cp311-cp311-win_amd64.whl.metadata (6.5 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading grpcio-1.68.1-cp311-cp311-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting tensorboard<2.19,>=2.18 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached keras-3.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting numpy<2.1.0,>=1.26.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading numpy-2.0.2-cp311-cp311-win_amd64.whl.metadata (59 kB)\n",
      "Collecting h5py>=3.11.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading h5py-3.12.1-cp311-cp311-win_amd64.whl.metadata (2.5 kB)\n",
      "Collecting ml-dtypes<0.5.0,>=0.4.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading ml_dtypes-0.4.1-cp311-cp311-win_amd64.whl.metadata (20 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.31.0-cp311-cp311-win_amd64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\kevin\\anaconda3\\envs\\facedetect\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.44.0)\n",
      "Collecting rich (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading optree-0.13.1-cp311-cp311-win_amd64.whl.metadata (48 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading charset_normalizer-3.4.0-cp311-cp311-win_amd64.whl.metadata (34 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading certifi-2024.8.30-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting MarkupSafe>=2.1.1 (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading MarkupSafe-3.0.2-cp311-cp311-win_amd64.whl.metadata (4.1 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\kevin\\anaconda3\\envs\\facedetect\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading tensorflow-2.18.0-cp311-cp311-win_amd64.whl (7.5 kB)\n",
      "Downloading tensorflow_intel-2.18.0-cp311-cp311-win_amd64.whl (390.2 MB)\n",
      "   ---------------------------------------- 0.0/390.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 4.5/390.2 MB 20.7 MB/s eta 0:00:19\n",
      "   - -------------------------------------- 10.2/390.2 MB 23.6 MB/s eta 0:00:17\n",
      "   - -------------------------------------- 15.7/390.2 MB 24.7 MB/s eta 0:00:16\n",
      "   -- ------------------------------------- 21.0/390.2 MB 24.5 MB/s eta 0:00:16\n",
      "   -- ------------------------------------- 26.7/390.2 MB 24.9 MB/s eta 0:00:15\n",
      "   --- ------------------------------------ 33.3/390.2 MB 26.1 MB/s eta 0:00:14\n",
      "   ---- ----------------------------------- 40.4/390.2 MB 27.0 MB/s eta 0:00:13\n",
      "   ---- ----------------------------------- 47.4/390.2 MB 27.7 MB/s eta 0:00:13\n",
      "   ----- ---------------------------------- 50.3/390.2 MB 26.3 MB/s eta 0:00:13\n",
      "   ----- ---------------------------------- 55.3/390.2 MB 25.9 MB/s eta 0:00:13\n",
      "   ------ --------------------------------- 61.6/390.2 MB 26.3 MB/s eta 0:00:13\n",
      "   ------- -------------------------------- 68.9/390.2 MB 27.0 MB/s eta 0:00:12\n",
      "   ------- -------------------------------- 75.2/390.2 MB 27.3 MB/s eta 0:00:12\n",
      "   -------- ------------------------------- 82.3/390.2 MB 27.6 MB/s eta 0:00:12\n",
      "   --------- ------------------------------ 89.7/390.2 MB 28.0 MB/s eta 0:00:11\n",
      "   --------- ------------------------------ 97.3/390.2 MB 28.6 MB/s eta 0:00:11\n",
      "   ---------- ---------------------------- 105.1/390.2 MB 29.1 MB/s eta 0:00:10\n",
      "   ---------- ---------------------------- 109.8/390.2 MB 29.2 MB/s eta 0:00:10\n",
      "   ----------- --------------------------- 116.4/390.2 MB 28.8 MB/s eta 0:00:10\n",
      "   ------------ -------------------------- 121.6/390.2 MB 29.1 MB/s eta 0:00:10\n",
      "   ------------ -------------------------- 123.5/390.2 MB 27.6 MB/s eta 0:00:10\n",
      "   ------------- ------------------------- 130.8/390.2 MB 27.9 MB/s eta 0:00:10\n",
      "   ------------- ------------------------- 138.4/390.2 MB 28.2 MB/s eta 0:00:09\n",
      "   -------------- ------------------------ 145.5/390.2 MB 28.5 MB/s eta 0:00:09\n",
      "   --------------- ----------------------- 152.6/390.2 MB 28.7 MB/s eta 0:00:09\n",
      "   ---------------- ---------------------- 160.4/390.2 MB 29.0 MB/s eta 0:00:08\n",
      "   ---------------- ---------------------- 168.0/390.2 MB 29.3 MB/s eta 0:00:08\n",
      "   ----------------- --------------------- 174.1/390.2 MB 29.4 MB/s eta 0:00:08\n",
      "   ----------------- --------------------- 174.9/390.2 MB 28.4 MB/s eta 0:00:08\n",
      "   ------------------ -------------------- 181.4/390.2 MB 28.4 MB/s eta 0:00:08\n",
      "   ------------------ -------------------- 188.7/390.2 MB 28.6 MB/s eta 0:00:08\n",
      "   ------------------- ------------------- 195.8/390.2 MB 28.7 MB/s eta 0:00:07\n",
      "   -------------------- ------------------ 202.9/390.2 MB 28.9 MB/s eta 0:00:07\n",
      "   --------------------- ----------------- 210.2/390.2 MB 29.0 MB/s eta 0:00:07\n",
      "   --------------------- ----------------- 217.6/390.2 MB 29.2 MB/s eta 0:00:06\n",
      "   ---------------------- ---------------- 224.4/390.2 MB 29.3 MB/s eta 0:00:06\n",
      "   ----------------------- --------------- 232.0/390.2 MB 29.4 MB/s eta 0:00:06\n",
      "   ----------------------- --------------- 239.6/390.2 MB 29.6 MB/s eta 0:00:06\n",
      "   ------------------------ -------------- 246.4/390.2 MB 29.7 MB/s eta 0:00:05\n",
      "   ------------------------- ------------- 250.3/390.2 MB 29.4 MB/s eta 0:00:05\n",
      "   ------------------------- ------------- 257.7/390.2 MB 29.5 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 265.0/390.2 MB 29.9 MB/s eta 0:00:05\n",
      "   --------------------------- ----------- 272.6/390.2 MB 30.1 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 280.0/390.2 MB 30.4 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 286.3/390.2 MB 30.5 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 293.9/390.2 MB 30.6 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 300.4/390.2 MB 30.6 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 308.3/390.2 MB 30.7 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 315.6/390.2 MB 31.4 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 316.1/390.2 MB 30.8 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 321.9/390.2 MB 30.6 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 328.7/390.2 MB 30.6 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 335.3/390.2 MB 30.6 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 342.1/390.2 MB 30.6 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 349.4/390.2 MB 30.5 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 355.7/390.2 MB 30.5 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 360.2/390.2 MB 30.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 366.7/390.2 MB 30.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 373.3/390.2 MB 30.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 380.1/390.2 MB 30.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  383.8/390.2 MB 30.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  389.8/390.2 MB 30.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.2 MB 30.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.2 MB 30.5 MB/s eta 0:00:01\n",
      "   --------------------------------------- 390.2/390.2 MB 28.5 MB/s eta 0:00:00\n",
      "Using cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Using cached flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Using cached gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading grpcio-1.68.1-cp311-cp311-win_amd64.whl (4.4 MB)\n",
      "   ---------------------------------------- 0.0/4.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 4.4/4.4 MB 29.6 MB/s eta 0:00:00\n",
      "Downloading h5py-3.12.1-cp311-cp311-win_amd64.whl (3.0 MB)\n",
      "   ---------------------------------------- 0.0/3.0 MB ? eta -:--:--\n",
      "   --------------------------- ------------ 2.1/3.0 MB 9.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.0/3.0 MB 11.7 MB/s eta 0:00:00\n",
      "Using cached keras-3.7.0-py3-none-any.whl (1.2 MB)\n",
      "Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "Downloading ml_dtypes-0.4.1-cp311-cp311-win_amd64.whl (126 kB)\n",
      "Downloading numpy-2.0.2-cp311-cp311-win_amd64.whl (15.9 MB)\n",
      "   ---------------------------------------- 0.0/15.9 MB ? eta -:--:--\n",
      "   --------------- ------------------------ 6.3/15.9 MB 32.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 13.9/15.9 MB 33.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.9/15.9 MB 27.8 MB/s eta 0:00:00\n",
      "Using cached opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading protobuf-5.29.1-cp310-abi3-win_amd64.whl (434 kB)\n",
      "Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "Downloading tensorflow_io_gcs_filesystem-0.31.0-cp311-cp311-win_amd64.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.5/1.5 MB 19.7 MB/s eta 0:00:00\n",
      "Using cached termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading wrapt-1.17.0-cp311-cp311-win_amd64.whl (38 kB)\n",
      "Downloading certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
      "Downloading charset_normalizer-3.4.0-cp311-cp311-win_amd64.whl (101 kB)\n",
      "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
      "Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Using cached namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.13.1-cp311-cp311-win_amd64.whl (292 kB)\n",
      "Downloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading MarkupSafe-3.0.2-cp311-cp311-win_amd64.whl (15 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, urllib3, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, protobuf, optree, opt-einsum, numpy, mdurl, MarkupSafe, markdown, idna, grpcio, google-pasta, gast, charset-normalizer, certifi, astunparse, absl-py, werkzeug, requests, ml-dtypes, markdown-it-py, h5py, tensorboard, rich, keras, tensorflow-intel, tensorflow\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.2.0\n",
      "    Uninstalling numpy-2.2.0:\n",
      "      Successfully uninstalled numpy-2.2.0\n",
      "Successfully installed MarkupSafe-3.0.2 absl-py-2.1.0 astunparse-1.6.3 certifi-2024.8.30 charset-normalizer-3.4.0 flatbuffers-24.3.25 gast-0.6.0 google-pasta-0.2.0 grpcio-1.68.1 h5py-3.12.1 idna-3.10 keras-3.7.0 libclang-18.1.1 markdown-3.7 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.4.1 namex-0.0.8 numpy-2.0.2 opt-einsum-3.4.0 optree-0.13.1 protobuf-5.29.1 requests-2.32.3 rich-13.9.4 tensorboard-2.18.0 tensorboard-data-server-0.7.2 tensorflow-2.18.0 tensorflow-intel-2.18.0 tensorflow-io-gcs-filesystem-0.31.0 termcolor-2.5.0 urllib3-2.2.3 werkzeug-3.1.3 wrapt-1.17.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The scripts f2py.exe and numpy-config.exe are installed in 'c:\\Users\\kevin\\anaconda3\\envs\\facedetect\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\kevin\\anaconda3\\envs\\facedetect\\Lib\\site-packages\\~umpy.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\kevin\\anaconda3\\envs\\facedetect\\Lib\\site-packages\\~umpy'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: The script markdown_py.exe is installed in 'c:\\Users\\kevin\\anaconda3\\envs\\facedetect\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script normalizer.exe is installed in 'c:\\Users\\kevin\\anaconda3\\envs\\facedetect\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script markdown-it.exe is installed in 'c:\\Users\\kevin\\anaconda3\\envs\\facedetect\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script tensorboard.exe is installed in 'c:\\Users\\kevin\\anaconda3\\envs\\facedetect\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts import_pb_to_tensorboard.exe, saved_model_cli.exe, tensorboard.exe, tf_upgrade_v2.exe, tflite_convert.exe, toco.exe and toco_from_protos.exe are installed in 'c:\\Users\\kevin\\anaconda3\\envs\\facedetect\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, Dropout, BatchNormalization, GlobalAveragePooling1D\n",
    "from tensorflow.keras.callbacks import Callback, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kevin\\anaconda3\\envs\\facedetect\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Conv1D(64, kernel_size=3, activation='relu', input_shape=(68, 2)),\n",
    "    BatchNormalization(),  # 모델 안정화\n",
    "    Dense(32 , activation='relu'),\n",
    "    Dense(32 , activation='relu'),\n",
    "    Dense(64 , activation='relu'),\n",
    "    Dense(128, activation='relu'), \n",
    "    Dense(256, activation='relu'), Dropout(0.5),\n",
    "    Dense(256, activation='relu'), Dropout(0.5),  \n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64 , activation='relu'),\n",
    "    Dense(32 , activation='relu'),\n",
    "    Dense(32 , activation='relu'),\n",
    "    \n",
    "    GlobalAveragePooling1D(),\n",
    "    Dense(3, activation='softmax') # 출력층\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_analyzer import NEpochCallback, NBatchCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_callback = NBatchCallback(n=10)\n",
    "epoch_callback = NEpochCallback(n= 2, filepath=\"./weights/\")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)\n",
    "model.compile(optimizer='nadam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m  9/521\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:04\u001b[0m 126ms/step - accuracy: 0.3517 - loss: 1.0976Batch 10: logs={'accuracy': 0.35859376192092896, 'loss': 1.0978196859359741}\n",
      "\u001b[1m 19/521\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:06\u001b[0m 132ms/step - accuracy: 0.3545 - loss: 1.0978Batch 20: logs={'accuracy': 0.34648436307907104, 'loss': 1.0987248420715332}\n",
      "\u001b[1m 29/521\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:07\u001b[0m 137ms/step - accuracy: 0.3498 - loss: 1.0981Batch 30: logs={'accuracy': 0.33645832538604736, 'loss': 1.0986422300338745}\n",
      "\u001b[1m 39/521\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:03\u001b[0m 131ms/step - accuracy: 0.3467 - loss: 1.0983Batch 40: logs={'accuracy': 0.33808594942092896, 'loss': 1.0984891653060913}\n",
      "\u001b[1m 49/521\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m59s\u001b[0m 127ms/step - accuracy: 0.3453 - loss: 1.0983 Batch 50: logs={'accuracy': 0.33937498927116394, 'loss': 1.0983706712722778}\n",
      "\u001b[1m 59/521\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m57s\u001b[0m 124ms/step - accuracy: 0.3443 - loss: 1.0983Batch 60: logs={'accuracy': 0.33776041865348816, 'loss': 1.098501443862915}\n",
      "\u001b[1m 69/521\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m54s\u001b[0m 121ms/step - accuracy: 0.3435 - loss: 1.0983Batch 70: logs={'accuracy': 0.3392857015132904, 'loss': 1.0983788967132568}\n",
      "\u001b[1m 79/521\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m53s\u001b[0m 121ms/step - accuracy: 0.3431 - loss: 1.0983Batch 80: logs={'accuracy': 0.34160155057907104, 'loss': 1.0980573892593384}\n",
      "\u001b[1m 89/521\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m51s\u001b[0m 120ms/step - accuracy: 0.3429 - loss: 1.0983Batch 90: logs={'accuracy': 0.34210067987442017, 'loss': 1.0979125499725342}\n",
      "\u001b[1m 99/521\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m50s\u001b[0m 119ms/step - accuracy: 0.3429 - loss: 1.0983Batch 100: logs={'accuracy': 0.34351563453674316, 'loss': 1.097931146621704}\n",
      "\u001b[1m109/521\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m48s\u001b[0m 117ms/step - accuracy: 0.3429 - loss: 1.0982Batch 110: logs={'accuracy': 0.34375, 'loss': 1.0977884531021118}\n",
      "\u001b[1m119/521\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m46s\u001b[0m 115ms/step - accuracy: 0.3430 - loss: 1.0982Batch 120: logs={'accuracy': 0.3462890684604645, 'loss': 1.097495675086975}\n",
      "\u001b[1m129/521\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m44s\u001b[0m 114ms/step - accuracy: 0.3433 - loss: 1.0981Batch 130: logs={'accuracy': 0.3467548191547394, 'loss': 1.0973718166351318}\n",
      "\u001b[1m139/521\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m43s\u001b[0m 114ms/step - accuracy: 0.3436 - loss: 1.0981Batch 140: logs={'accuracy': 0.3488839268684387, 'loss': 1.0973256826400757}\n",
      "\u001b[1m149/521\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m42s\u001b[0m 114ms/step - accuracy: 0.3441 - loss: 1.0980Batch 150: logs={'accuracy': 0.35333332419395447, 'loss': 1.0968811511993408}\n",
      "\u001b[1m159/521\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m41s\u001b[0m 114ms/step - accuracy: 0.3448 - loss: 1.0979Batch 160: logs={'accuracy': 0.3570312559604645, 'loss': 1.0960667133331299}\n",
      "\u001b[1m169/521\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m40s\u001b[0m 114ms/step - accuracy: 0.3456 - loss: 1.0978Batch 170: logs={'accuracy': 0.36070773005485535, 'loss': 1.0946630239486694}\n",
      "\u001b[1m179/521\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m39s\u001b[0m 115ms/step - accuracy: 0.3466 - loss: 1.0975Batch 180: logs={'accuracy': 0.3667100667953491, 'loss': 1.091926097869873}\n",
      "\u001b[1m189/521\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m38s\u001b[0m 115ms/step - accuracy: 0.3478 - loss: 1.0971Batch 190: logs={'accuracy': 0.37298518419265747, 'loss': 1.0873572826385498}\n",
      "\u001b[1m199/521\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m36s\u001b[0m 114ms/step - accuracy: 0.3491 - loss: 1.0966Batch 200: logs={'accuracy': 0.3777734339237213, 'loss': 1.08226478099823}\n",
      "\u001b[1m209/521\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m35s\u001b[0m 115ms/step - accuracy: 0.3507 - loss: 1.0957Batch 210: logs={'accuracy': 0.384672611951828, 'loss': 1.075614094734192}\n",
      "\u001b[1m219/521\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m34s\u001b[0m 114ms/step - accuracy: 0.3523 - loss: 1.0947Batch 220: logs={'accuracy': 0.3902343809604645, 'loss': 1.0701074600219727}\n",
      "\u001b[1m229/521\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m33s\u001b[0m 115ms/step - accuracy: 0.3541 - loss: 1.0935Batch 230: logs={'accuracy': 0.395108699798584, 'loss': 1.0640437602996826}\n",
      "\u001b[1m239/521\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m32s\u001b[0m 115ms/step - accuracy: 0.3559 - loss: 1.0922Batch 240: logs={'accuracy': 0.40074869990348816, 'loss': 1.0581198930740356}\n",
      "\u001b[1m249/521\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m31s\u001b[0m 115ms/step - accuracy: 0.3578 - loss: 1.0907Batch 250: logs={'accuracy': 0.40684375166893005, 'loss': 1.0528382062911987}\n",
      "\u001b[1m259/521\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m30s\u001b[0m 115ms/step - accuracy: 0.3598 - loss: 1.0891Batch 260: logs={'accuracy': 0.411268025636673, 'loss': 1.046886682510376}\n",
      "\u001b[1m269/521\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m29s\u001b[0m 115ms/step - accuracy: 0.3618 - loss: 1.0875Batch 270: logs={'accuracy': 0.41588541865348816, 'loss': 1.042789340019226}\n",
      "\u001b[1m279/521\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m27s\u001b[0m 115ms/step - accuracy: 0.3638 - loss: 1.0858Batch 280: logs={'accuracy': 0.41969865560531616, 'loss': 1.0377134084701538}\n",
      "\u001b[1m289/521\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m26s\u001b[0m 114ms/step - accuracy: 0.3658 - loss: 1.0841Batch 290: logs={'accuracy': 0.42405712604522705, 'loss': 1.0328023433685303}\n",
      "\u001b[1m299/521\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m25s\u001b[0m 114ms/step - accuracy: 0.3678 - loss: 1.0823Batch 300: logs={'accuracy': 0.4288802146911621, 'loss': 1.0278265476226807}\n",
      "\u001b[1m309/521\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 113ms/step - accuracy: 0.3698 - loss: 1.0805Batch 310: logs={'accuracy': 0.4331653118133545, 'loss': 1.0233405828475952}\n",
      "\u001b[1m319/521\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 113ms/step - accuracy: 0.3719 - loss: 1.0786Batch 320: logs={'accuracy': 0.4364257752895355, 'loss': 1.0189540386199951}\n",
      "\u001b[1m329/521\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 112ms/step - accuracy: 0.3739 - loss: 1.0767Batch 330: logs={'accuracy': 0.43996211886405945, 'loss': 1.014879822731018}\n",
      "\u001b[1m339/521\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 112ms/step - accuracy: 0.3759 - loss: 1.0749Batch 340: logs={'accuracy': 0.44345128536224365, 'loss': 1.0110565423965454}\n",
      "\u001b[1m349/521\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 112ms/step - accuracy: 0.3779 - loss: 1.0730Batch 350: logs={'accuracy': 0.44703125953674316, 'loss': 1.0063021183013916}\n",
      "\u001b[1m359/521\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 112ms/step - accuracy: 0.3798 - loss: 1.0711Batch 360: logs={'accuracy': 0.4495008587837219, 'loss': 1.0030466318130493}\n",
      "\u001b[1m369/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 112ms/step - accuracy: 0.3817 - loss: 1.0692Batch 370: logs={'accuracy': 0.45209038257598877, 'loss': 0.9998146891593933}\n",
      "\u001b[1m379/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 112ms/step - accuracy: 0.3836 - loss: 1.0673Batch 380: logs={'accuracy': 0.45464637875556946, 'loss': 0.996233344078064}\n",
      "\u001b[1m389/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 113ms/step - accuracy: 0.3855 - loss: 1.0654Batch 390: logs={'accuracy': 0.45801281929016113, 'loss': 0.9930144548416138}\n",
      "\u001b[1m399/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m13s\u001b[0m 113ms/step - accuracy: 0.3874 - loss: 1.0636Batch 400: logs={'accuracy': 0.4608203172683716, 'loss': 0.9894539713859558}\n",
      "\u001b[1m409/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m12s\u001b[0m 113ms/step - accuracy: 0.3892 - loss: 1.0617Batch 410: logs={'accuracy': 0.46360519528388977, 'loss': 0.9857689142227173}\n",
      "\u001b[1m419/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m11s\u001b[0m 113ms/step - accuracy: 0.3910 - loss: 1.0599Batch 420: logs={'accuracy': 0.4667782783508301, 'loss': 0.9821275472640991}\n",
      "\u001b[1m429/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m10s\u001b[0m 114ms/step - accuracy: 0.3928 - loss: 1.0580Batch 430: logs={'accuracy': 0.4688953459262848, 'loss': 0.9788726568222046}\n",
      "\u001b[1m439/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m9s\u001b[0m 114ms/step - accuracy: 0.3945 - loss: 1.0562Batch 440: logs={'accuracy': 0.4711647629737854, 'loss': 0.9755666851997375}\n",
      "\u001b[1m449/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m8s\u001b[0m 114ms/step - accuracy: 0.3963 - loss: 1.0544Batch 450: logs={'accuracy': 0.47350695729255676, 'loss': 0.9721807837486267}\n",
      "\u001b[1m459/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m7s\u001b[0m 114ms/step - accuracy: 0.3980 - loss: 1.0526Batch 460: logs={'accuracy': 0.4756114184856415, 'loss': 0.9698140621185303}\n",
      "\u001b[1m469/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m5s\u001b[0m 113ms/step - accuracy: 0.3997 - loss: 1.0508Batch 470: logs={'accuracy': 0.47789227962493896, 'loss': 0.966791570186615}\n",
      "\u001b[1m479/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m4s\u001b[0m 113ms/step - accuracy: 0.4013 - loss: 1.0490Batch 480: logs={'accuracy': 0.48017579317092896, 'loss': 0.9640153646469116}\n",
      "\u001b[1m489/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m3s\u001b[0m 113ms/step - accuracy: 0.4029 - loss: 1.0472Batch 490: logs={'accuracy': 0.48152104020118713, 'loss': 0.9609522819519043}\n",
      "\u001b[1m499/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m2s\u001b[0m 113ms/step - accuracy: 0.4045 - loss: 1.0455Batch 500: logs={'accuracy': 0.4827812612056732, 'loss': 0.9590159058570862}\n",
      "\u001b[1m509/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - accuracy: 0.4061 - loss: 1.0437Batch 510: logs={'accuracy': 0.48390012979507446, 'loss': 0.9564592838287354}\n",
      "\u001b[1m519/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.4076 - loss: 1.0420Batch 520: logs={'accuracy': 0.4853966236114502, 'loss': 0.9540742635726929}\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 112ms/step - accuracy: 0.4080 - loss: 1.0415\n",
      "Epoch 2/10\n",
      "\u001b[1m  8/521\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m50s\u001b[0m 99ms/step - accuracy: 0.5641 - loss: 0.8180Batch 530: logs={'accuracy': 0.5668402910232544, 'loss': 0.7965917587280273}\n",
      "\u001b[1m 18/521\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m49s\u001b[0m 98ms/step - accuracy: 0.5598 - loss: 0.8133Batch 540: logs={'accuracy': 0.5612664222717285, 'loss': 0.8155059814453125}\n",
      "\u001b[1m 28/521\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m47s\u001b[0m 97ms/step - accuracy: 0.5580 - loss: 0.8155Batch 550: logs={'accuracy': 0.5501077771186829, 'loss': 0.8231469988822937}\n",
      "\u001b[1m 38/521\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m47s\u001b[0m 98ms/step - accuracy: 0.5563 - loss: 0.8167Batch 560: logs={'accuracy': 0.5520833134651184, 'loss': 0.8204325437545776}\n",
      "\u001b[1m 48/521\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m48s\u001b[0m 102ms/step - accuracy: 0.5553 - loss: 0.8189Batch 570: logs={'accuracy': 0.5540497303009033, 'loss': 0.8294110894203186}\n",
      "\u001b[1m 58/521\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m48s\u001b[0m 106ms/step - accuracy: 0.5557 - loss: 0.8205Batch 580: logs={'accuracy': 0.5622351765632629, 'loss': 0.8247775435447693}\n",
      "\u001b[1m 68/521\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m47s\u001b[0m 105ms/step - accuracy: 0.5569 - loss: 0.8206Batch 590: logs={'accuracy': 0.5643116235733032, 'loss': 0.8210707902908325}\n",
      "\u001b[1m 78/521\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m45s\u001b[0m 104ms/step - accuracy: 0.5580 - loss: 0.8205Batch 600: logs={'accuracy': 0.5678402185440063, 'loss': 0.8179576992988586}\n",
      "\u001b[1m 88/521\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m44s\u001b[0m 103ms/step - accuracy: 0.5591 - loss: 0.8202Batch 610: logs={'accuracy': 0.5667135119438171, 'loss': 0.8181598782539368}\n",
      "\u001b[1m 98/521\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m43s\u001b[0m 103ms/step - accuracy: 0.5596 - loss: 0.8201Batch 620: logs={'accuracy': 0.5632102489471436, 'loss': 0.8200229406356812}\n",
      "\u001b[1m108/521\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m42s\u001b[0m 103ms/step - accuracy: 0.5599 - loss: 0.8199Batch 630: logs={'accuracy': 0.5619266033172607, 'loss': 0.8169713020324707}\n",
      "\u001b[1m118/521\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m41s\u001b[0m 103ms/step - accuracy: 0.5601 - loss: 0.8197Batch 640: logs={'accuracy': 0.5630252361297607, 'loss': 0.8171697854995728}\n",
      "\u001b[1m128/521\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m40s\u001b[0m 102ms/step - accuracy: 0.5604 - loss: 0.8195Batch 650: logs={'accuracy': 0.5648618936538696, 'loss': 0.816929280757904}\n",
      "\u001b[1m138/521\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m38s\u001b[0m 101ms/step - accuracy: 0.5607 - loss: 0.8192Batch 660: logs={'accuracy': 0.5646920204162598, 'loss': 0.8140926957130432}\n",
      "\u001b[1m148/521\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m37s\u001b[0m 101ms/step - accuracy: 0.5611 - loss: 0.8189Batch 670: logs={'accuracy': 0.5658556818962097, 'loss': 0.8155449628829956}\n",
      "\u001b[1m158/521\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m36s\u001b[0m 101ms/step - accuracy: 0.5614 - loss: 0.8186Batch 680: logs={'accuracy': 0.5681505799293518, 'loss': 0.8136964440345764}\n",
      "\u001b[1m168/521\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m35s\u001b[0m 101ms/step - accuracy: 0.5619 - loss: 0.8183Batch 690: logs={'accuracy': 0.5685558319091797, 'loss': 0.8131555914878845}\n",
      "\u001b[1m178/521\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m34s\u001b[0m 101ms/step - accuracy: 0.5623 - loss: 0.8179Batch 700: logs={'accuracy': 0.5698323845863342, 'loss': 0.8126975297927856}\n",
      "\u001b[1m188/521\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m33s\u001b[0m 100ms/step - accuracy: 0.5627 - loss: 0.8177Batch 710: logs={'accuracy': 0.5702711343765259, 'loss': 0.813654363155365}\n",
      "\u001b[1m198/521\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m32s\u001b[0m 100ms/step - accuracy: 0.5631 - loss: 0.8175Batch 720: logs={'accuracy': 0.5704695582389832, 'loss': 0.814513623714447}\n",
      "\u001b[1m208/521\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m31s\u001b[0m 100ms/step - accuracy: 0.5635 - loss: 0.8173Batch 730: logs={'accuracy': 0.5701255798339844, 'loss': 0.8146859407424927}\n",
      "\u001b[1m218/521\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m30s\u001b[0m 99ms/step - accuracy: 0.5638 - loss: 0.8172Batch 740: logs={'accuracy': 0.5704908967018127, 'loss': 0.8129090070724487}\n",
      "\u001b[1m228/521\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m29s\u001b[0m 99ms/step - accuracy: 0.5641 - loss: 0.8170Batch 750: logs={'accuracy': 0.5709607005119324, 'loss': 0.8119149804115295}\n",
      "\u001b[1m238/521\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m28s\u001b[0m 100ms/step - accuracy: 0.5644 - loss: 0.8168Batch 760: logs={'accuracy': 0.5701163411140442, 'loss': 0.8117467164993286}\n",
      "\u001b[1m248/521\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m27s\u001b[0m 102ms/step - accuracy: 0.5646 - loss: 0.8165Batch 770: logs={'accuracy': 0.5708772540092468, 'loss': 0.8110185861587524}\n",
      "\u001b[1m258/521\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m26s\u001b[0m 102ms/step - accuracy: 0.5649 - loss: 0.8163Batch 780: logs={'accuracy': 0.5711570978164673, 'loss': 0.8109071254730225}\n",
      "\u001b[1m268/521\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m25s\u001b[0m 103ms/step - accuracy: 0.5651 - loss: 0.8161Batch 790: logs={'accuracy': 0.5718517899513245, 'loss': 0.811068058013916}\n",
      "\u001b[1m278/521\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m25s\u001b[0m 104ms/step - accuracy: 0.5654 - loss: 0.8159Batch 800: logs={'accuracy': 0.5732806921005249, 'loss': 0.8098811507225037}\n",
      "\u001b[1m288/521\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 104ms/step - accuracy: 0.5657 - loss: 0.8157Batch 810: logs={'accuracy': 0.5743944644927979, 'loss': 0.8080534934997559}\n",
      "\u001b[1m298/521\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 104ms/step - accuracy: 0.5660 - loss: 0.8154Batch 820: logs={'accuracy': 0.5748589038848877, 'loss': 0.8085935115814209}\n",
      "\u001b[1m308/521\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 104ms/step - accuracy: 0.5663 - loss: 0.8152Batch 830: logs={'accuracy': 0.5754955410957336, 'loss': 0.8072856664657593}\n",
      "\u001b[1m318/521\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 104ms/step - accuracy: 0.5666 - loss: 0.8149Batch 840: logs={'accuracy': 0.5760923027992249, 'loss': 0.8064165711402893}\n",
      "\u001b[1m328/521\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 104ms/step - accuracy: 0.5669 - loss: 0.8147Batch 850: logs={'accuracy': 0.5765102505683899, 'loss': 0.8061846494674683}\n",
      "\u001b[1m338/521\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 103ms/step - accuracy: 0.5672 - loss: 0.8144Batch 860: logs={'accuracy': 0.5762583017349243, 'loss': 0.8047173619270325}\n",
      "\u001b[1m348/521\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 103ms/step - accuracy: 0.5674 - loss: 0.8141Batch 870: logs={'accuracy': 0.5764461159706116, 'loss': 0.804521381855011}\n",
      "\u001b[1m358/521\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 102ms/step - accuracy: 0.5677 - loss: 0.8139Batch 880: logs={'accuracy': 0.5762969851493835, 'loss': 0.8041020631790161}\n",
      "\u001b[1m368/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 102ms/step - accuracy: 0.5679 - loss: 0.8136Batch 890: logs={'accuracy': 0.5760289430618286, 'loss': 0.8037639260292053}\n",
      "\u001b[1m378/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 102ms/step - accuracy: 0.5681 - loss: 0.8133Batch 900: logs={'accuracy': 0.5767232775688171, 'loss': 0.8029866218566895}\n",
      "\u001b[1m388/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 101ms/step - accuracy: 0.5684 - loss: 0.8130Batch 910: logs={'accuracy': 0.5782455205917358, 'loss': 0.8018801808357239}\n",
      "\u001b[1m398/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m12s\u001b[0m 101ms/step - accuracy: 0.5686 - loss: 0.8128Batch 920: logs={'accuracy': 0.5786145329475403, 'loss': 0.8017469048500061}\n",
      "\u001b[1m408/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m11s\u001b[0m 101ms/step - accuracy: 0.5689 - loss: 0.8125Batch 930: logs={'accuracy': 0.5786789655685425, 'loss': 0.801806628704071}\n",
      "\u001b[1m418/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m10s\u001b[0m 100ms/step - accuracy: 0.5691 - loss: 0.8122Batch 940: logs={'accuracy': 0.5781063437461853, 'loss': 0.8014421463012695}\n",
      "\u001b[1m428/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m9s\u001b[0m 100ms/step - accuracy: 0.5693 - loss: 0.8120Batch 950: logs={'accuracy': 0.5790173411369324, 'loss': 0.8001132607460022}\n",
      "\u001b[1m438/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m8s\u001b[0m 101ms/step - accuracy: 0.5695 - loss: 0.8117Batch 960: logs={'accuracy': 0.5796910524368286, 'loss': 0.7994088530540466}\n",
      "\u001b[1m448/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m7s\u001b[0m 101ms/step - accuracy: 0.5698 - loss: 0.8114Batch 970: logs={'accuracy': 0.5805261731147766, 'loss': 0.7981398105621338}\n",
      "\u001b[1m458/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m6s\u001b[0m 101ms/step - accuracy: 0.5700 - loss: 0.8111Batch 980: logs={'accuracy': 0.5809844732284546, 'loss': 0.7975471615791321}\n",
      "\u001b[1m468/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m5s\u001b[0m 101ms/step - accuracy: 0.5702 - loss: 0.8108Batch 990: logs={'accuracy': 0.5811067223548889, 'loss': 0.7975078225135803}\n",
      "\u001b[1m478/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - accuracy: 0.5705 - loss: 0.8105Batch 1000: logs={'accuracy': 0.5818926095962524, 'loss': 0.7966822981834412}\n",
      "\u001b[1m488/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m3s\u001b[0m 101ms/step - accuracy: 0.5707 - loss: 0.8102Batch 1010: logs={'accuracy': 0.5823907256126404, 'loss': 0.7957460284233093}\n",
      "\u001b[1m498/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - accuracy: 0.5709 - loss: 0.8100Batch 1020: logs={'accuracy': 0.5823365449905396, 'loss': 0.795966625213623}\n",
      "\u001b[1m508/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - accuracy: 0.5712 - loss: 0.8097Batch 1030: logs={'accuracy': 0.5823305249214172, 'loss': 0.7957876920700073}\n",
      "\u001b[1m518/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.5714 - loss: 0.8094Batch 1040: logs={'accuracy': 0.5832580924034119, 'loss': 0.7949259877204895}\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.5715 - loss: 0.8093Model weights saved for epoch 2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 101ms/step - accuracy: 0.5715 - loss: 0.8093\n",
      "Epoch 3/10\n",
      "\u001b[1m  7/521\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m41s\u001b[0m 81ms/step - accuracy: 0.5987 - loss: 0.7556Batch 1050: logs={'accuracy': 0.603515625, 'loss': 0.765823483467102}\n",
      "\u001b[1m 17/521\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m44s\u001b[0m 88ms/step - accuracy: 0.5993 - loss: 0.7597Batch 1060: logs={'accuracy': 0.5941840410232544, 'loss': 0.7631770372390747}\n",
      "\u001b[1m 27/521\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m42s\u001b[0m 87ms/step - accuracy: 0.5977 - loss: 0.7586Batch 1070: logs={'accuracy': 0.595703125, 'loss': 0.7553032636642456}\n",
      "\u001b[1m 37/521\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m42s\u001b[0m 87ms/step - accuracy: 0.5971 - loss: 0.7583Batch 1080: logs={'accuracy': 0.5972450375556946, 'loss': 0.7558714151382446}\n",
      "\u001b[1m 47/521\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m41s\u001b[0m 88ms/step - accuracy: 0.5974 - loss: 0.7577Batch 1090: logs={'accuracy': 0.5989583134651184, 'loss': 0.7536768913269043}\n",
      "\u001b[1m 57/521\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m40s\u001b[0m 88ms/step - accuracy: 0.5978 - loss: 0.7568Batch 1100: logs={'accuracy': 0.5981950163841248, 'loss': 0.7526236176490784}\n",
      "\u001b[1m 67/521\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m40s\u001b[0m 88ms/step - accuracy: 0.5979 - loss: 0.7564Batch 1110: logs={'accuracy': 0.597771167755127, 'loss': 0.7586277723312378}\n",
      "\u001b[1m 77/521\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m39s\u001b[0m 89ms/step - accuracy: 0.5980 - loss: 0.7566Batch 1120: logs={'accuracy': 0.6000601053237915, 'loss': 0.7562777996063232}\n",
      "\u001b[1m 87/521\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m38s\u001b[0m 90ms/step - accuracy: 0.5983 - loss: 0.7566Batch 1130: logs={'accuracy': 0.6004971861839294, 'loss': 0.7578140497207642}\n",
      "\u001b[1m 97/521\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m38s\u001b[0m 92ms/step - accuracy: 0.5986 - loss: 0.7567Batch 1140: logs={'accuracy': 0.6030771732330322, 'loss': 0.7552934885025024}\n",
      "\u001b[1m107/521\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m38s\u001b[0m 92ms/step - accuracy: 0.5990 - loss: 0.7567Batch 1150: logs={'accuracy': 0.6029369235038757, 'loss': 0.7571349143981934}\n",
      "\u001b[1m117/521\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m37s\u001b[0m 92ms/step - accuracy: 0.5993 - loss: 0.7568Batch 1160: logs={'accuracy': 0.6024894118309021, 'loss': 0.757448136806488}\n",
      "\u001b[1m127/521\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m36s\u001b[0m 92ms/step - accuracy: 0.5996 - loss: 0.7569Batch 1170: logs={'accuracy': 0.60406494140625, 'loss': 0.758171558380127}\n",
      "\u001b[1m137/521\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m35s\u001b[0m 92ms/step - accuracy: 0.6000 - loss: 0.7570Batch 1180: logs={'accuracy': 0.6050158739089966, 'loss': 0.7590267062187195}\n",
      "\u001b[1m147/521\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m34s\u001b[0m 92ms/step - accuracy: 0.6003 - loss: 0.7571Batch 1190: logs={'accuracy': 0.6053103804588318, 'loss': 0.7598796486854553}\n",
      "\u001b[1m157/521\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m33s\u001b[0m 91ms/step - accuracy: 0.6007 - loss: 0.7572Batch 1200: logs={'accuracy': 0.607594907283783, 'loss': 0.7581901550292969}\n",
      "\u001b[1m167/521\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m32s\u001b[0m 91ms/step - accuracy: 0.6011 - loss: 0.7573Batch 1210: logs={'accuracy': 0.607607901096344, 'loss': 0.758181095123291}\n",
      "\u001b[1m177/521\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m31s\u001b[0m 91ms/step - accuracy: 0.6015 - loss: 0.7573Batch 1220: logs={'accuracy': 0.6085410714149475, 'loss': 0.7572479248046875}\n",
      "\u001b[1m187/521\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m30s\u001b[0m 91ms/step - accuracy: 0.6019 - loss: 0.7572Batch 1230: logs={'accuracy': 0.6092919111251831, 'loss': 0.7561308145523071}\n",
      "\u001b[1m197/521\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m29s\u001b[0m 90ms/step - accuracy: 0.6023 - loss: 0.7572Batch 1240: logs={'accuracy': 0.6090987920761108, 'loss': 0.7565973997116089}\n",
      "\u001b[1m207/521\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m28s\u001b[0m 90ms/step - accuracy: 0.6027 - loss: 0.7571Batch 1250: logs={'accuracy': 0.6100135445594788, 'loss': 0.7546167969703674}\n",
      "\u001b[1m217/521\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m27s\u001b[0m 91ms/step - accuracy: 0.6030 - loss: 0.7570Batch 1260: logs={'accuracy': 0.6107009649276733, 'loss': 0.7545496821403503}\n",
      "\u001b[1m227/521\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m26s\u001b[0m 91ms/step - accuracy: 0.6033 - loss: 0.7569Batch 1270: logs={'accuracy': 0.6101288199424744, 'loss': 0.754016637802124}\n",
      "\u001b[1m237/521\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m25s\u001b[0m 91ms/step - accuracy: 0.6036 - loss: 0.7568Batch 1280: logs={'accuracy': 0.6101956367492676, 'loss': 0.7540637254714966}\n",
      "\u001b[1m247/521\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m25s\u001b[0m 92ms/step - accuracy: 0.6039 - loss: 0.7566Batch 1290: logs={'accuracy': 0.6105090975761414, 'loss': 0.7535935044288635}\n",
      "\u001b[1m257/521\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 94ms/step - accuracy: 0.6042 - loss: 0.7565Batch 1300: logs={'accuracy': 0.6114643812179565, 'loss': 0.7533796429634094}\n",
      "\u001b[1m267/521\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 95ms/step - accuracy: 0.6045 - loss: 0.7564Batch 1310: logs={'accuracy': 0.6120277643203735, 'loss': 0.7536060214042664}\n",
      "\u001b[1m277/521\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 96ms/step - accuracy: 0.6048 - loss: 0.7563Batch 1320: logs={'accuracy': 0.6133655309677124, 'loss': 0.752305805683136}\n",
      "\u001b[1m287/521\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 97ms/step - accuracy: 0.6051 - loss: 0.7562Batch 1330: logs={'accuracy': 0.6130913496017456, 'loss': 0.7531335353851318}\n",
      "\u001b[1m297/521\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 97ms/step - accuracy: 0.6053 - loss: 0.7560Batch 1340: logs={'accuracy': 0.6142250299453735, 'loss': 0.7529042363166809}\n",
      "\u001b[1m307/521\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 98ms/step - accuracy: 0.6056 - loss: 0.7559Batch 1350: logs={'accuracy': 0.6142451167106628, 'loss': 0.7528672218322754}\n",
      "\u001b[1m317/521\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 97ms/step - accuracy: 0.6059 - loss: 0.7558Batch 1360: logs={'accuracy': 0.6148044466972351, 'loss': 0.7519592046737671}\n",
      "\u001b[1m327/521\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 97ms/step - accuracy: 0.6062 - loss: 0.7557Batch 1370: logs={'accuracy': 0.6156631112098694, 'loss': 0.7509293556213379}\n",
      "\u001b[1m337/521\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 97ms/step - accuracy: 0.6065 - loss: 0.7556Batch 1380: logs={'accuracy': 0.6153846383094788, 'loss': 0.7515764236450195}\n",
      "\u001b[1m347/521\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 97ms/step - accuracy: 0.6067 - loss: 0.7554Batch 1390: logs={'accuracy': 0.6157507300376892, 'loss': 0.7502956986427307}\n",
      "\u001b[1m357/521\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 98ms/step - accuracy: 0.6070 - loss: 0.7553Batch 1400: logs={'accuracy': 0.6159436106681824, 'loss': 0.75044184923172}\n",
      "\u001b[1m367/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 98ms/step - accuracy: 0.6072 - loss: 0.7552Batch 1410: logs={'accuracy': 0.61548912525177, 'loss': 0.7514095306396484}\n",
      "\u001b[1m377/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 97ms/step - accuracy: 0.6075 - loss: 0.7551Batch 1420: logs={'accuracy': 0.6164847612380981, 'loss': 0.7506551742553711}\n",
      "\u001b[1m387/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 98ms/step - accuracy: 0.6077 - loss: 0.7549Batch 1430: logs={'accuracy': 0.6171875, 'loss': 0.7507675886154175}\n",
      "\u001b[1m397/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m12s\u001b[0m 98ms/step - accuracy: 0.6080 - loss: 0.7548Batch 1440: logs={'accuracy': 0.6178156137466431, 'loss': 0.7507951259613037}\n",
      "\u001b[1m407/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m11s\u001b[0m 98ms/step - accuracy: 0.6082 - loss: 0.7547Batch 1450: logs={'accuracy': 0.617915153503418, 'loss': 0.7511909604072571}\n",
      "\u001b[1m417/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m10s\u001b[0m 98ms/step - accuracy: 0.6084 - loss: 0.7547Batch 1460: logs={'accuracy': 0.6188696026802063, 'loss': 0.7505736351013184}\n",
      "\u001b[1m427/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m9s\u001b[0m 97ms/step - accuracy: 0.6087 - loss: 0.7545Batch 1470: logs={'accuracy': 0.6205278635025024, 'loss': 0.7495510578155518}\n",
      "\u001b[1m437/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m8s\u001b[0m 97ms/step - accuracy: 0.6090 - loss: 0.7544Batch 1480: logs={'accuracy': 0.6213613152503967, 'loss': 0.7489382028579712}\n",
      "\u001b[1m447/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m7s\u001b[0m 97ms/step - accuracy: 0.6093 - loss: 0.7543Batch 1490: logs={'accuracy': 0.6214774250984192, 'loss': 0.7487550377845764}\n",
      "\u001b[1m457/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m6s\u001b[0m 97ms/step - accuracy: 0.6095 - loss: 0.7542Batch 1500: logs={'accuracy': 0.6223901510238647, 'loss': 0.747808575630188}\n",
      "\u001b[1m467/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m5s\u001b[0m 97ms/step - accuracy: 0.6098 - loss: 0.7540Batch 1510: logs={'accuracy': 0.6228799223899841, 'loss': 0.7476546168327332}\n",
      "\u001b[1m477/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 0.6101 - loss: 0.7539Batch 1520: logs={'accuracy': 0.623806893825531, 'loss': 0.7471602559089661}\n",
      "\u001b[1m487/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m3s\u001b[0m 98ms/step - accuracy: 0.6104 - loss: 0.7538Batch 1530: logs={'accuracy': 0.6235591769218445, 'loss': 0.7473162412643433}\n",
      "\u001b[1m497/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - accuracy: 0.6107 - loss: 0.7536Batch 1540: logs={'accuracy': 0.6244980096817017, 'loss': 0.7469677925109863}\n",
      "\u001b[1m507/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - accuracy: 0.6109 - loss: 0.7535Batch 1550: logs={'accuracy': 0.6253536939620972, 'loss': 0.746421217918396}\n",
      "\u001b[1m517/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.6112 - loss: 0.7533Batch 1560: logs={'accuracy': 0.6259199976921082, 'loss': 0.7458577156066895}\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 99ms/step - accuracy: 0.6114 - loss: 0.7533\n",
      "Epoch 4/10\n",
      "\u001b[1m  6/521\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m51s\u001b[0m 101ms/step - accuracy: 0.6961 - loss: 0.6604Batch 1570: logs={'accuracy': 0.6953125, 'loss': 0.6819033622741699}\n",
      "\u001b[1m 16/521\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m50s\u001b[0m 100ms/step - accuracy: 0.6934 - loss: 0.6776Batch 1580: logs={'accuracy': 0.6920955777168274, 'loss': 0.6883623600006104}\n",
      "\u001b[1m 26/521\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m53s\u001b[0m 108ms/step - accuracy: 0.6910 - loss: 0.6839Batch 1590: logs={'accuracy': 0.6837384104728699, 'loss': 0.6954498291015625}\n",
      "\u001b[1m 36/521\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m52s\u001b[0m 108ms/step - accuracy: 0.6886 - loss: 0.6885Batch 1600: logs={'accuracy': 0.6782094836235046, 'loss': 0.707168698310852}\n",
      "\u001b[1m 46/521\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m49s\u001b[0m 104ms/step - accuracy: 0.6863 - loss: 0.6934Batch 1610: logs={'accuracy': 0.6763630509376526, 'loss': 0.7141984701156616}\n",
      "\u001b[1m 56/521\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m47s\u001b[0m 102ms/step - accuracy: 0.6847 - loss: 0.6970Batch 1620: logs={'accuracy': 0.6773574352264404, 'loss': 0.7141558527946472}\n",
      "\u001b[1m 66/521\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m45s\u001b[0m 101ms/step - accuracy: 0.6835 - loss: 0.6998Batch 1630: logs={'accuracy': 0.678521454334259, 'loss': 0.7125946283340454}\n",
      "\u001b[1m 76/521\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m44s\u001b[0m 101ms/step - accuracy: 0.6829 - loss: 0.7013Batch 1640: logs={'accuracy': 0.6790787577629089, 'loss': 0.7092355489730835}\n",
      "\u001b[1m 86/521\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m44s\u001b[0m 102ms/step - accuracy: 0.6825 - loss: 0.7022Batch 1650: logs={'accuracy': 0.678071141242981, 'loss': 0.7089549899101257}\n",
      "\u001b[1m 96/521\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m43s\u001b[0m 103ms/step - accuracy: 0.6820 - loss: 0.7029Batch 1660: logs={'accuracy': 0.678398847579956, 'loss': 0.7064757347106934}\n",
      "\u001b[1m106/521\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m42s\u001b[0m 102ms/step - accuracy: 0.6816 - loss: 0.7033Batch 1670: logs={'accuracy': 0.6774240732192993, 'loss': 0.7086219191551208}\n",
      "\u001b[1m116/521\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m42s\u001b[0m 104ms/step - accuracy: 0.6811 - loss: 0.7039Batch 1680: logs={'accuracy': 0.6754807829856873, 'loss': 0.7100660800933838}\n",
      "\u001b[1m126/521\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m40s\u001b[0m 103ms/step - accuracy: 0.6806 - loss: 0.7045Batch 1690: logs={'accuracy': 0.6732898354530334, 'loss': 0.7107384204864502}\n",
      "\u001b[1m136/521\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m39s\u001b[0m 103ms/step - accuracy: 0.6800 - loss: 0.7050Batch 1700: logs={'accuracy': 0.6724452376365662, 'loss': 0.7124502658843994}\n",
      "\u001b[1m146/521\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m38s\u001b[0m 102ms/step - accuracy: 0.6796 - loss: 0.7054Batch 1710: logs={'accuracy': 0.6738945841789246, 'loss': 0.7106622457504272}\n",
      "\u001b[1m156/521\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m36s\u001b[0m 101ms/step - accuracy: 0.6792 - loss: 0.7057Batch 1720: logs={'accuracy': 0.6736166477203369, 'loss': 0.7097862362861633}\n",
      "\u001b[1m166/521\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m35s\u001b[0m 100ms/step - accuracy: 0.6789 - loss: 0.7059Batch 1730: logs={'accuracy': 0.6735591292381287, 'loss': 0.7087469100952148}\n",
      "\u001b[1m176/521\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m34s\u001b[0m 100ms/step - accuracy: 0.6786 - loss: 0.7060Batch 1740: logs={'accuracy': 0.6750529408454895, 'loss': 0.706610381603241}\n",
      "\u001b[1m186/521\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m33s\u001b[0m 100ms/step - accuracy: 0.6784 - loss: 0.7060Batch 1750: logs={'accuracy': 0.6757603883743286, 'loss': 0.7060183882713318}\n",
      "\u001b[1m196/521\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m32s\u001b[0m 100ms/step - accuracy: 0.6783 - loss: 0.7060Batch 1760: logs={'accuracy': 0.6777442693710327, 'loss': 0.7040382027626038}\n",
      "\u001b[1m206/521\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m31s\u001b[0m 100ms/step - accuracy: 0.6783 - loss: 0.7059Batch 1770: logs={'accuracy': 0.6782155632972717, 'loss': 0.70395427942276}\n",
      "\u001b[1m216/521\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m30s\u001b[0m 100ms/step - accuracy: 0.6783 - loss: 0.7058Batch 1780: logs={'accuracy': 0.6781033873558044, 'loss': 0.7039526104927063}\n",
      "\u001b[1m226/521\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m29s\u001b[0m 100ms/step - accuracy: 0.6783 - loss: 0.7057Batch 1790: logs={'accuracy': 0.6782075762748718, 'loss': 0.7034671306610107}\n",
      "\u001b[1m236/521\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m28s\u001b[0m 99ms/step - accuracy: 0.6783 - loss: 0.7056Batch 1800: logs={'accuracy': 0.6797863841056824, 'loss': 0.7022931575775146}\n",
      "\u001b[1m246/521\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m27s\u001b[0m 98ms/step - accuracy: 0.6784 - loss: 0.7055Batch 1810: logs={'accuracy': 0.680035412311554, 'loss': 0.7024080157279968}\n",
      "\u001b[1m256/521\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m25s\u001b[0m 98ms/step - accuracy: 0.6785 - loss: 0.7053Batch 1820: logs={'accuracy': 0.6811466217041016, 'loss': 0.7016564011573792}\n",
      "\u001b[1m266/521\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 98ms/step - accuracy: 0.6786 - loss: 0.7052Batch 1830: logs={'accuracy': 0.6815308928489685, 'loss': 0.7017912864685059}\n",
      "\u001b[1m276/521\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 97ms/step - accuracy: 0.6787 - loss: 0.7051Batch 1840: logs={'accuracy': 0.6818310022354126, 'loss': 0.7017130851745605}\n",
      "\u001b[1m286/521\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 97ms/step - accuracy: 0.6788 - loss: 0.7049Batch 1850: logs={'accuracy': 0.6823279857635498, 'loss': 0.7007179260253906}\n",
      "\u001b[1m296/521\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 97ms/step - accuracy: 0.6789 - loss: 0.7048Batch 1860: logs={'accuracy': 0.683054506778717, 'loss': 0.6994572877883911}\n",
      "\u001b[1m306/521\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 97ms/step - accuracy: 0.6791 - loss: 0.7046Batch 1870: logs={'accuracy': 0.6841154098510742, 'loss': 0.6980670690536499}\n",
      "\u001b[1m316/521\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 97ms/step - accuracy: 0.6793 - loss: 0.7044Batch 1880: logs={'accuracy': 0.6846165060997009, 'loss': 0.6973375678062439}\n",
      "\u001b[1m326/521\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 97ms/step - accuracy: 0.6794 - loss: 0.7041Batch 1890: logs={'accuracy': 0.6849436163902283, 'loss': 0.6969715356826782}\n",
      "\u001b[1m336/521\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 97ms/step - accuracy: 0.6796 - loss: 0.7039Batch 1900: logs={'accuracy': 0.6855526566505432, 'loss': 0.6964046359062195}\n",
      "\u001b[1m346/521\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 97ms/step - accuracy: 0.6798 - loss: 0.7037Batch 1910: logs={'accuracy': 0.6858339309692383, 'loss': 0.6955856680870056}\n",
      "\u001b[1m356/521\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 97ms/step - accuracy: 0.6799 - loss: 0.7034Batch 1920: logs={'accuracy': 0.6858368515968323, 'loss': 0.6952811479568481}\n",
      "\u001b[1m366/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 97ms/step - accuracy: 0.6801 - loss: 0.7032Batch 1930: logs={'accuracy': 0.6866911053657532, 'loss': 0.6938804984092712}\n",
      "\u001b[1m376/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 97ms/step - accuracy: 0.6803 - loss: 0.7030Batch 1940: logs={'accuracy': 0.6870026588439941, 'loss': 0.6932857632637024}\n",
      "\u001b[1m386/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 97ms/step - accuracy: 0.6805 - loss: 0.7027Batch 1950: logs={'accuracy': 0.6874192357063293, 'loss': 0.6923591494560242}\n",
      "\u001b[1m396/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m12s\u001b[0m 97ms/step - accuracy: 0.6806 - loss: 0.7024Batch 1960: logs={'accuracy': 0.6872048377990723, 'loss': 0.6921736001968384}\n",
      "\u001b[1m406/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - accuracy: 0.6808 - loss: 0.7022Batch 1970: logs={'accuracy': 0.6881718635559082, 'loss': 0.690764307975769}\n",
      "\u001b[1m416/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m10s\u001b[0m 97ms/step - accuracy: 0.6810 - loss: 0.7019Batch 1980: logs={'accuracy': 0.688249409198761, 'loss': 0.6905051469802856}\n",
      "\u001b[1m426/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m9s\u001b[0m 97ms/step - accuracy: 0.6812 - loss: 0.7016Batch 1990: logs={'accuracy': 0.6886343955993652, 'loss': 0.6896862387657166}\n",
      "\u001b[1m436/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m8s\u001b[0m 97ms/step - accuracy: 0.6813 - loss: 0.7013Batch 2000: logs={'accuracy': 0.6890910863876343, 'loss': 0.6891407370567322}\n",
      "\u001b[1m446/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m7s\u001b[0m 97ms/step - accuracy: 0.6815 - loss: 0.7011Batch 2010: logs={'accuracy': 0.6900342702865601, 'loss': 0.6874655485153198}\n",
      "\u001b[1m456/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m6s\u001b[0m 96ms/step - accuracy: 0.6817 - loss: 0.7008Batch 2020: logs={'accuracy': 0.690799355506897, 'loss': 0.686383068561554}\n",
      "\u001b[1m466/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m5s\u001b[0m 96ms/step - accuracy: 0.6819 - loss: 0.7004Batch 2030: logs={'accuracy': 0.6916153430938721, 'loss': 0.6844873428344727}\n",
      "\u001b[1m476/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 0.6821 - loss: 0.7001Batch 2040: logs={'accuracy': 0.6922169923782349, 'loss': 0.6834360361099243}\n",
      "\u001b[1m486/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m3s\u001b[0m 96ms/step - accuracy: 0.6823 - loss: 0.6997Batch 2050: logs={'accuracy': 0.692681610584259, 'loss': 0.6830325722694397}\n",
      "\u001b[1m496/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - accuracy: 0.6825 - loss: 0.6994Batch 2060: logs={'accuracy': 0.6928917169570923, 'loss': 0.6833654642105103}\n",
      "\u001b[1m506/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - accuracy: 0.6828 - loss: 0.6991Batch 2070: logs={'accuracy': 0.6934325695037842, 'loss': 0.6827026605606079}\n",
      "\u001b[1m516/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.6830 - loss: 0.6987Batch 2080: logs={'accuracy': 0.6938467025756836, 'loss': 0.6819552183151245}\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.6831 - loss: 0.6986Model weights saved for epoch 4\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 95ms/step - accuracy: 0.6831 - loss: 0.6985\n",
      "Epoch 5/10\n",
      "\u001b[1m  5/521\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m46s\u001b[0m 90ms/step - accuracy: 0.7461 - loss: 0.6605Batch 2090: logs={'accuracy': 0.7200520634651184, 'loss': 0.677445113658905}\n",
      "\u001b[1m 15/521\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m42s\u001b[0m 85ms/step - accuracy: 0.7317 - loss: 0.6579Batch 2100: logs={'accuracy': 0.72509765625, 'loss': 0.651397705078125}\n",
      "\u001b[1m 25/521\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m42s\u001b[0m 85ms/step - accuracy: 0.7290 - loss: 0.6532Batch 2110: logs={'accuracy': 0.7265625, 'loss': 0.6374197006225586}\n",
      "\u001b[1m 35/521\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m41s\u001b[0m 85ms/step - accuracy: 0.7283 - loss: 0.6485Batch 2120: logs={'accuracy': 0.7241753339767456, 'loss': 0.6406759023666382}\n",
      "\u001b[1m 45/521\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m40s\u001b[0m 85ms/step - accuracy: 0.7279 - loss: 0.6458Batch 2130: logs={'accuracy': 0.7265625, 'loss': 0.634124755859375}\n",
      "\u001b[1m 55/521\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m40s\u001b[0m 86ms/step - accuracy: 0.7276 - loss: 0.6438Batch 2140: logs={'accuracy': 0.7267020344734192, 'loss': 0.6363070607185364}\n",
      "\u001b[1m 65/521\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m39s\u001b[0m 86ms/step - accuracy: 0.7276 - loss: 0.6426Batch 2150: logs={'accuracy': 0.7260890007019043, 'loss': 0.6377228498458862}\n",
      "\u001b[1m 75/521\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m38s\u001b[0m 86ms/step - accuracy: 0.7273 - loss: 0.6420Batch 2160: logs={'accuracy': 0.7234786152839661, 'loss': 0.6397104263305664}\n",
      "\u001b[1m 85/521\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m37s\u001b[0m 86ms/step - accuracy: 0.7267 - loss: 0.6419Batch 2170: logs={'accuracy': 0.7213844656944275, 'loss': 0.641135573387146}\n",
      "\u001b[1m 95/521\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m37s\u001b[0m 87ms/step - accuracy: 0.7261 - loss: 0.6417Batch 2180: logs={'accuracy': 0.7198079228401184, 'loss': 0.6419616341590881}\n",
      "\u001b[1m105/521\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m37s\u001b[0m 90ms/step - accuracy: 0.7255 - loss: 0.6417Batch 2190: logs={'accuracy': 0.721255898475647, 'loss': 0.6416898965835571}\n",
      "\u001b[1m115/521\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m37s\u001b[0m 92ms/step - accuracy: 0.7252 - loss: 0.6416Batch 2200: logs={'accuracy': 0.7225215435028076, 'loss': 0.6385313272476196}\n",
      "\u001b[1m125/521\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m36s\u001b[0m 93ms/step - accuracy: 0.7250 - loss: 0.6413Batch 2210: logs={'accuracy': 0.722284197807312, 'loss': 0.6378880143165588}\n",
      "\u001b[1m135/521\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m36s\u001b[0m 94ms/step - accuracy: 0.7248 - loss: 0.6411Batch 2220: logs={'accuracy': 0.721794605255127, 'loss': 0.6388642191886902}\n",
      "\u001b[1m145/521\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m35s\u001b[0m 95ms/step - accuracy: 0.7246 - loss: 0.6409Batch 2230: logs={'accuracy': 0.7233518958091736, 'loss': 0.6369778513908386}\n",
      "\u001b[1m155/521\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m35s\u001b[0m 96ms/step - accuracy: 0.7245 - loss: 0.6406Batch 2240: logs={'accuracy': 0.7234575152397156, 'loss': 0.6373048424720764}\n",
      "\u001b[1m165/521\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m34s\u001b[0m 97ms/step - accuracy: 0.7244 - loss: 0.6404Batch 2250: logs={'accuracy': 0.7233622074127197, 'loss': 0.6367630362510681}\n",
      "\u001b[1m175/521\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m33s\u001b[0m 97ms/step - accuracy: 0.7244 - loss: 0.6402Batch 2260: logs={'accuracy': 0.7234108448028564, 'loss': 0.6369460821151733}\n",
      "\u001b[1m185/521\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m32s\u001b[0m 97ms/step - accuracy: 0.7243 - loss: 0.6400Batch 2270: logs={'accuracy': 0.7235803008079529, 'loss': 0.6355698108673096}\n",
      "\u001b[1m195/521\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m31s\u001b[0m 98ms/step - accuracy: 0.7243 - loss: 0.6397Batch 2280: logs={'accuracy': 0.7245296835899353, 'loss': 0.6339967250823975}\n",
      "\u001b[1m205/521\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m30s\u001b[0m 98ms/step - accuracy: 0.7243 - loss: 0.6395Batch 2290: logs={'accuracy': 0.7251971960067749, 'loss': 0.6336559057235718}\n",
      "\u001b[1m215/521\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m30s\u001b[0m 98ms/step - accuracy: 0.7244 - loss: 0.6392Batch 2300: logs={'accuracy': 0.7245731949806213, 'loss': 0.6336026787757874}\n",
      "\u001b[1m225/521\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m29s\u001b[0m 99ms/step - accuracy: 0.7244 - loss: 0.6389Batch 2310: logs={'accuracy': 0.7245229482650757, 'loss': 0.6333587765693665}\n",
      "\u001b[1m235/521\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m28s\u001b[0m 98ms/step - accuracy: 0.7244 - loss: 0.6387Batch 2320: logs={'accuracy': 0.7245762944221497, 'loss': 0.6325857043266296}\n",
      "\u001b[1m245/521\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m27s\u001b[0m 98ms/step - accuracy: 0.7244 - loss: 0.6384Batch 2330: logs={'accuracy': 0.7245299816131592, 'loss': 0.6331728100776672}\n",
      "\u001b[1m255/521\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m26s\u001b[0m 98ms/step - accuracy: 0.7244 - loss: 0.6382Batch 2340: logs={'accuracy': 0.725616455078125, 'loss': 0.632457971572876}\n",
      "\u001b[1m265/521\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m25s\u001b[0m 98ms/step - accuracy: 0.7245 - loss: 0.6380Batch 2350: logs={'accuracy': 0.7244184613227844, 'loss': 0.6338787078857422}\n",
      "\u001b[1m275/521\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 98ms/step - accuracy: 0.7245 - loss: 0.6378Batch 2360: logs={'accuracy': 0.7248924374580383, 'loss': 0.6329814791679382}\n",
      "\u001b[1m285/521\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 97ms/step - accuracy: 0.7245 - loss: 0.6377Batch 2370: logs={'accuracy': 0.7251420617103577, 'loss': 0.6330175995826721}\n",
      "\u001b[1m295/521\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 97ms/step - accuracy: 0.7245 - loss: 0.6375Batch 2380: logs={'accuracy': 0.7251900434494019, 'loss': 0.6330984830856323}\n",
      "\u001b[1m305/521\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 97ms/step - accuracy: 0.7245 - loss: 0.6374Batch 2390: logs={'accuracy': 0.7256944179534912, 'loss': 0.6324307322502136}\n",
      "\u001b[1m315/521\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 98ms/step - accuracy: 0.7246 - loss: 0.6372Batch 2400: logs={'accuracy': 0.7260927557945251, 'loss': 0.6319969892501831}\n",
      "\u001b[1m325/521\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 98ms/step - accuracy: 0.7246 - loss: 0.6371Batch 2410: logs={'accuracy': 0.726730227470398, 'loss': 0.6312569379806519}\n",
      "\u001b[1m335/521\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 97ms/step - accuracy: 0.7247 - loss: 0.6369Batch 2420: logs={'accuracy': 0.7266089916229248, 'loss': 0.6310745477676392}\n",
      "\u001b[1m345/521\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 97ms/step - accuracy: 0.7247 - loss: 0.6367Batch 2430: logs={'accuracy': 0.7269237637519836, 'loss': 0.6309748888015747}\n",
      "\u001b[1m355/521\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 97ms/step - accuracy: 0.7248 - loss: 0.6365Batch 2440: logs={'accuracy': 0.727352499961853, 'loss': 0.63019859790802}\n",
      "\u001b[1m365/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 97ms/step - accuracy: 0.7249 - loss: 0.6364Batch 2450: logs={'accuracy': 0.7275230288505554, 'loss': 0.6294845938682556}\n",
      "\u001b[1m375/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 97ms/step - accuracy: 0.7249 - loss: 0.6362Batch 2460: logs={'accuracy': 0.7272897362709045, 'loss': 0.629454493522644}\n",
      "\u001b[1m385/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 97ms/step - accuracy: 0.7250 - loss: 0.6360Batch 2470: logs={'accuracy': 0.7274327874183655, 'loss': 0.6286928057670593}\n",
      "\u001b[1m395/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m12s\u001b[0m 97ms/step - accuracy: 0.7251 - loss: 0.6358Batch 2480: logs={'accuracy': 0.7274108529090881, 'loss': 0.6284801363945007}\n",
      "\u001b[1m405/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - accuracy: 0.7251 - loss: 0.6356Batch 2490: logs={'accuracy': 0.7278324961662292, 'loss': 0.6277194619178772}\n",
      "\u001b[1m415/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m10s\u001b[0m 96ms/step - accuracy: 0.7252 - loss: 0.6354Batch 2500: logs={'accuracy': 0.7281399965286255, 'loss': 0.6273402571678162}\n",
      "\u001b[1m425/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m9s\u001b[0m 96ms/step - accuracy: 0.7253 - loss: 0.6352Batch 2510: logs={'accuracy': 0.7281947135925293, 'loss': 0.6271771788597107}\n",
      "\u001b[1m435/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m8s\u001b[0m 96ms/step - accuracy: 0.7253 - loss: 0.6350Batch 2520: logs={'accuracy': 0.7289994359016418, 'loss': 0.6265169978141785}\n",
      "\u001b[1m445/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m7s\u001b[0m 97ms/step - accuracy: 0.7254 - loss: 0.6348Batch 2530: logs={'accuracy': 0.7289097309112549, 'loss': 0.6261954307556152}\n",
      "\u001b[1m455/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m6s\u001b[0m 97ms/step - accuracy: 0.7255 - loss: 0.6347Batch 2540: logs={'accuracy': 0.7290467619895935, 'loss': 0.6260161399841309}\n",
      "\u001b[1m465/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m5s\u001b[0m 98ms/step - accuracy: 0.7256 - loss: 0.6345Batch 2550: logs={'accuracy': 0.7291275262832642, 'loss': 0.6258420944213867}\n",
      "\u001b[1m475/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m4s\u001b[0m 100ms/step - accuracy: 0.7256 - loss: 0.6343Batch 2560: logs={'accuracy': 0.7296973466873169, 'loss': 0.6253481507301331}\n",
      "\u001b[1m485/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m3s\u001b[0m 102ms/step - accuracy: 0.7257 - loss: 0.6341Batch 2570: logs={'accuracy': 0.7298257350921631, 'loss': 0.6250277757644653}\n",
      "\u001b[1m495/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m2s\u001b[0m 103ms/step - accuracy: 0.7258 - loss: 0.6339Batch 2580: logs={'accuracy': 0.7298544645309448, 'loss': 0.62539142370224}\n",
      "\u001b[1m505/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - accuracy: 0.7259 - loss: 0.6337Batch 2590: logs={'accuracy': 0.730376124382019, 'loss': 0.6238804459571838}\n",
      "\u001b[1m515/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.7260 - loss: 0.6335Batch 2600: logs={'accuracy': 0.7306352853775024, 'loss': 0.6230446100234985}\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 104ms/step - accuracy: 0.7261 - loss: 0.6334\n",
      "Epoch 6/10\n",
      "\u001b[1m  4/521\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:05\u001b[0m 126ms/step - accuracy: 0.7210 - loss: 0.6157Batch 2610: logs={'accuracy': 0.729687511920929, 'loss': 0.6058171391487122}\n",
      "\u001b[1m 14/521\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:07\u001b[0m 134ms/step - accuracy: 0.7300 - loss: 0.6120Batch 2620: logs={'accuracy': 0.731249988079071, 'loss': 0.6169159412384033}\n",
      "\u001b[1m 24/521\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:05\u001b[0m 132ms/step - accuracy: 0.7296 - loss: 0.6146Batch 2630: logs={'accuracy': 0.7309374809265137, 'loss': 0.6106002330780029}\n",
      "\u001b[1m 34/521\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:03\u001b[0m 131ms/step - accuracy: 0.7303 - loss: 0.6147Batch 2640: logs={'accuracy': 0.7337053418159485, 'loss': 0.6169393062591553}\n",
      "\u001b[1m 44/521\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:01\u001b[0m 128ms/step - accuracy: 0.7313 - loss: 0.6142Batch 2650: logs={'accuracy': 0.7345486283302307, 'loss': 0.610159695148468}\n",
      "\u001b[1m 54/521\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m58s\u001b[0m 126ms/step - accuracy: 0.7321 - loss: 0.6131Batch 2660: logs={'accuracy': 0.7365056872367859, 'loss': 0.6048101186752319}\n",
      "\u001b[1m 64/521\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m58s\u001b[0m 127ms/step - accuracy: 0.7326 - loss: 0.6122Batch 2670: logs={'accuracy': 0.7338942289352417, 'loss': 0.6095195412635803}\n",
      "\u001b[1m 74/521\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m56s\u001b[0m 127ms/step - accuracy: 0.7329 - loss: 0.6115Batch 2680: logs={'accuracy': 0.7351041436195374, 'loss': 0.6045579314231873}\n",
      "\u001b[1m 84/521\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m55s\u001b[0m 127ms/step - accuracy: 0.7333 - loss: 0.6104Batch 2690: logs={'accuracy': 0.7381433844566345, 'loss': 0.601085364818573}\n",
      "\u001b[1m 94/521\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m54s\u001b[0m 127ms/step - accuracy: 0.7338 - loss: 0.6095Batch 2700: logs={'accuracy': 0.7387335300445557, 'loss': 0.6011593341827393}\n",
      "\u001b[1m104/521\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m53s\u001b[0m 128ms/step - accuracy: 0.7343 - loss: 0.6088Batch 2710: logs={'accuracy': 0.7383184432983398, 'loss': 0.601886510848999}\n",
      "\u001b[1m114/521\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m51s\u001b[0m 127ms/step - accuracy: 0.7346 - loss: 0.6082Batch 2720: logs={'accuracy': 0.73777174949646, 'loss': 0.6043069362640381}\n",
      "\u001b[1m124/521\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m50s\u001b[0m 127ms/step - accuracy: 0.7349 - loss: 0.6080Batch 2730: logs={'accuracy': 0.7386249899864197, 'loss': 0.6049102544784546}\n",
      "\u001b[1m134/521\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m49s\u001b[0m 128ms/step - accuracy: 0.7352 - loss: 0.6078Batch 2740: logs={'accuracy': 0.7380787134170532, 'loss': 0.6058182120323181}\n",
      "\u001b[1m144/521\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m49s\u001b[0m 132ms/step - accuracy: 0.7354 - loss: 0.6076Batch 2750: logs={'accuracy': 0.7387392520904541, 'loss': 0.6047483086585999}\n",
      "\u001b[1m154/521\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m48s\u001b[0m 132ms/step - accuracy: 0.7357 - loss: 0.6073Batch 2760: logs={'accuracy': 0.7401713728904724, 'loss': 0.6024726629257202}\n",
      "\u001b[1m164/521\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m46s\u001b[0m 131ms/step - accuracy: 0.7360 - loss: 0.6070Batch 2770: logs={'accuracy': 0.7409090995788574, 'loss': 0.6026429533958435}\n",
      "\u001b[1m174/521\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m45s\u001b[0m 131ms/step - accuracy: 0.7362 - loss: 0.6068Batch 2780: logs={'accuracy': 0.7411160469055176, 'loss': 0.6017536520957947}\n",
      "\u001b[1m184/521\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m44s\u001b[0m 131ms/step - accuracy: 0.7365 - loss: 0.6065Batch 2790: logs={'accuracy': 0.7406672239303589, 'loss': 0.6022273302078247}\n",
      "\u001b[1m194/521\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m42s\u001b[0m 131ms/step - accuracy: 0.7367 - loss: 0.6062Batch 2800: logs={'accuracy': 0.7421875, 'loss': 0.5990017056465149}\n",
      "\u001b[1m204/521\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m41s\u001b[0m 131ms/step - accuracy: 0.7370 - loss: 0.6059Batch 2810: logs={'accuracy': 0.7427972555160522, 'loss': 0.5974200367927551}\n",
      "\u001b[1m214/521\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m40s\u001b[0m 131ms/step - accuracy: 0.7373 - loss: 0.6054Batch 2820: logs={'accuracy': 0.742732584476471, 'loss': 0.5976008772850037}\n",
      "\u001b[1m224/521\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m38s\u001b[0m 130ms/step - accuracy: 0.7375 - loss: 0.6051Batch 2830: logs={'accuracy': 0.7429513931274414, 'loss': 0.5974419713020325}\n",
      "\u001b[1m234/521\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m37s\u001b[0m 131ms/step - accuracy: 0.7378 - loss: 0.6048Batch 2840: logs={'accuracy': 0.7431848645210266, 'loss': 0.5984314680099487}\n",
      "\u001b[1m244/521\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m36s\u001b[0m 130ms/step - accuracy: 0.7380 - loss: 0.6045Batch 2850: logs={'accuracy': 0.7438775300979614, 'loss': 0.5972806811332703}\n",
      "\u001b[1m254/521\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m34s\u001b[0m 130ms/step - accuracy: 0.7383 - loss: 0.6042Batch 2860: logs={'accuracy': 0.7439950704574585, 'loss': 0.5971733927726746}\n",
      "\u001b[1m264/521\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m33s\u001b[0m 130ms/step - accuracy: 0.7385 - loss: 0.6040Batch 2870: logs={'accuracy': 0.7433372735977173, 'loss': 0.5973874926567078}\n",
      "\u001b[1m274/521\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m32s\u001b[0m 130ms/step - accuracy: 0.7387 - loss: 0.6037Batch 2880: logs={'accuracy': 0.7442329525947571, 'loss': 0.5963959693908691}\n",
      "\u001b[1m284/521\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m30s\u001b[0m 130ms/step - accuracy: 0.7389 - loss: 0.6034Batch 2890: logs={'accuracy': 0.7447916865348816, 'loss': 0.5948982238769531}\n",
      "\u001b[1m294/521\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m29s\u001b[0m 131ms/step - accuracy: 0.7391 - loss: 0.6031Batch 2900: logs={'accuracy': 0.7448887825012207, 'loss': 0.5950308442115784}\n",
      "\u001b[1m304/521\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m28s\u001b[0m 132ms/step - accuracy: 0.7393 - loss: 0.6029Batch 2910: logs={'accuracy': 0.7454661726951599, 'loss': 0.5941662192344666}\n",
      "\u001b[1m314/521\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m27s\u001b[0m 131ms/step - accuracy: 0.7395 - loss: 0.6026Batch 2920: logs={'accuracy': 0.7457093000411987, 'loss': 0.5939226150512695}\n",
      "\u001b[1m324/521\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m25s\u001b[0m 131ms/step - accuracy: 0.7397 - loss: 0.6023Batch 2930: logs={'accuracy': 0.745721161365509, 'loss': 0.5937090516090393}\n",
      "\u001b[1m334/521\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 130ms/step - accuracy: 0.7398 - loss: 0.6021Batch 2940: logs={'accuracy': 0.7458255887031555, 'loss': 0.5936212539672852}\n",
      "\u001b[1m344/521\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 130ms/step - accuracy: 0.7400 - loss: 0.6018Batch 2950: logs={'accuracy': 0.7461956739425659, 'loss': 0.5928731560707092}\n",
      "\u001b[1m354/521\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 130ms/step - accuracy: 0.7402 - loss: 0.6015Batch 2960: logs={'accuracy': 0.7464128732681274, 'loss': 0.5922799706459045}\n",
      "\u001b[1m364/521\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 130ms/step - accuracy: 0.7404 - loss: 0.6013Batch 2970: logs={'accuracy': 0.7467893958091736, 'loss': 0.5926896929740906}\n",
      "\u001b[1m374/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 129ms/step - accuracy: 0.7405 - loss: 0.6011Batch 2980: logs={'accuracy': 0.746749997138977, 'loss': 0.5925148129463196}\n",
      "\u001b[1m384/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 129ms/step - accuracy: 0.7407 - loss: 0.6008Batch 2990: logs={'accuracy': 0.7464488744735718, 'loss': 0.5930248498916626}\n",
      "\u001b[1m394/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m16s\u001b[0m 129ms/step - accuracy: 0.7408 - loss: 0.6006Batch 3000: logs={'accuracy': 0.7469343543052673, 'loss': 0.5922656059265137}\n",
      "\u001b[1m404/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m14s\u001b[0m 128ms/step - accuracy: 0.7410 - loss: 0.6004Batch 3010: logs={'accuracy': 0.7475887537002563, 'loss': 0.5913833975791931}\n",
      "\u001b[1m414/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m13s\u001b[0m 128ms/step - accuracy: 0.7412 - loss: 0.6002Batch 3020: logs={'accuracy': 0.7482869029045105, 'loss': 0.5900289416313171}\n",
      "\u001b[1m424/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m12s\u001b[0m 128ms/step - accuracy: 0.7413 - loss: 0.5999Batch 3030: logs={'accuracy': 0.7486948370933533, 'loss': 0.5892913937568665}\n",
      "\u001b[1m434/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m11s\u001b[0m 128ms/step - accuracy: 0.7415 - loss: 0.5997Batch 3040: logs={'accuracy': 0.7486709952354431, 'loss': 0.5893301963806152}\n",
      "\u001b[1m444/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m9s\u001b[0m 127ms/step - accuracy: 0.7417 - loss: 0.5994Batch 3050: logs={'accuracy': 0.7491748332977295, 'loss': 0.5884286165237427}\n",
      "\u001b[1m454/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m8s\u001b[0m 128ms/step - accuracy: 0.7418 - loss: 0.5992Batch 3060: logs={'accuracy': 0.7493131756782532, 'loss': 0.5880324244499207}\n",
      "\u001b[1m464/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m7s\u001b[0m 128ms/step - accuracy: 0.7420 - loss: 0.5990Batch 3070: logs={'accuracy': 0.7491095662117004, 'loss': 0.5883117914199829}\n",
      "\u001b[1m474/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m5s\u001b[0m 128ms/step - accuracy: 0.7421 - loss: 0.5987Batch 3080: logs={'accuracy': 0.7494572401046753, 'loss': 0.5874892473220825}\n",
      "\u001b[1m484/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m4s\u001b[0m 128ms/step - accuracy: 0.7423 - loss: 0.5985Batch 3090: logs={'accuracy': 0.75, 'loss': 0.5867067575454712}\n",
      "\u001b[1m494/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - accuracy: 0.7425 - loss: 0.5983Batch 3100: logs={'accuracy': 0.7500473260879517, 'loss': 0.5866272449493408}\n",
      "\u001b[1m504/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m2s\u001b[0m 128ms/step - accuracy: 0.7426 - loss: 0.5980Batch 3110: logs={'accuracy': 0.7501701712608337, 'loss': 0.5858569145202637}\n",
      "\u001b[1m514/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - accuracy: 0.7428 - loss: 0.5978Batch 3120: logs={'accuracy': 0.7503640651702881, 'loss': 0.5854899287223816}\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - accuracy: 0.7429 - loss: 0.5976Model weights saved for epoch 6\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 129ms/step - accuracy: 0.7429 - loss: 0.5976\n",
      "Epoch 7/10\n",
      "\u001b[1m  3/521\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:04\u001b[0m 124ms/step - accuracy: 0.7053 - loss: 0.6998Batch 3130: logs={'accuracy': 0.744140625, 'loss': 0.634524941444397}\n",
      "\u001b[1m 13/521\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:03\u001b[0m 125ms/step - accuracy: 0.7362 - loss: 0.6366Batch 3140: logs={'accuracy': 0.7416294813156128, 'loss': 0.6182636022567749}\n",
      "\u001b[1m 23/521\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:02\u001b[0m 125ms/step - accuracy: 0.7387 - loss: 0.6266Batch 3150: logs={'accuracy': 0.7477213740348816, 'loss': 0.6041661500930786}\n",
      "\u001b[1m 33/521\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m59s\u001b[0m 123ms/step - accuracy: 0.7429 - loss: 0.6173 Batch 3160: logs={'accuracy': 0.7564338445663452, 'loss': 0.5874188542366028}\n",
      "\u001b[1m 43/521\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m57s\u001b[0m 120ms/step - accuracy: 0.7460 - loss: 0.6099Batch 3170: logs={'accuracy': 0.7551491260528564, 'loss': 0.5820007920265198}\n",
      "\u001b[1m 53/521\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m55s\u001b[0m 119ms/step - accuracy: 0.7478 - loss: 0.6050Batch 3180: logs={'accuracy': 0.7560763955116272, 'loss': 0.583450198173523}\n",
      "\u001b[1m 63/521\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m54s\u001b[0m 119ms/step - accuracy: 0.7490 - loss: 0.6016Batch 3190: logs={'accuracy': 0.755615234375, 'loss': 0.5813176035881042}\n",
      "\u001b[1m 73/521\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m53s\u001b[0m 119ms/step - accuracy: 0.7500 - loss: 0.5986Batch 3200: logs={'accuracy': 0.7566511631011963, 'loss': 0.5789648294448853}\n",
      "\u001b[1m 83/521\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m53s\u001b[0m 122ms/step - accuracy: 0.7510 - loss: 0.5959Batch 3210: logs={'accuracy': 0.7580915093421936, 'loss': 0.5758475065231323}\n",
      "\u001b[1m 93/521\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m52s\u001b[0m 122ms/step - accuracy: 0.7518 - loss: 0.5936Batch 3220: logs={'accuracy': 0.7590591907501221, 'loss': 0.5726726651191711}\n",
      "\u001b[1m103/521\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m51s\u001b[0m 123ms/step - accuracy: 0.7525 - loss: 0.5915Batch 3230: logs={'accuracy': 0.7584885954856873, 'loss': 0.5717417001724243}\n",
      "\u001b[1m113/521\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m50s\u001b[0m 124ms/step - accuracy: 0.7529 - loss: 0.5899Batch 3240: logs={'accuracy': 0.7558936476707458, 'loss': 0.5754579901695251}\n",
      "\u001b[1m123/521\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m49s\u001b[0m 124ms/step - accuracy: 0.7533 - loss: 0.5886Batch 3250: logs={'accuracy': 0.7578755021095276, 'loss': 0.5730154514312744}\n",
      "\u001b[1m133/521\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m47s\u001b[0m 123ms/step - accuracy: 0.7536 - loss: 0.5875Batch 3260: logs={'accuracy': 0.7572878003120422, 'loss': 0.5740570425987244}\n",
      "\u001b[1m143/521\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m46s\u001b[0m 122ms/step - accuracy: 0.7539 - loss: 0.5865Batch 3270: logs={'accuracy': 0.75830078125, 'loss': 0.5730108022689819}\n",
      "\u001b[1m153/521\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m44s\u001b[0m 122ms/step - accuracy: 0.7542 - loss: 0.5856Batch 3280: logs={'accuracy': 0.7581676244735718, 'loss': 0.5741972923278809}\n",
      "\u001b[1m163/521\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m43s\u001b[0m 121ms/step - accuracy: 0.7544 - loss: 0.5850Batch 3290: logs={'accuracy': 0.7583364844322205, 'loss': 0.5739879012107849}\n",
      "\u001b[1m173/521\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m41s\u001b[0m 120ms/step - accuracy: 0.7546 - loss: 0.5844Batch 3300: logs={'accuracy': 0.7568247318267822, 'loss': 0.5759595632553101}\n",
      "\u001b[1m183/521\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m40s\u001b[0m 120ms/step - accuracy: 0.7547 - loss: 0.5839Batch 3310: logs={'accuracy': 0.75611412525177, 'loss': 0.57599937915802}\n",
      "\u001b[1m193/521\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m39s\u001b[0m 120ms/step - accuracy: 0.7548 - loss: 0.5835Batch 3320: logs={'accuracy': 0.7562016844749451, 'loss': 0.5751254558563232}\n",
      "\u001b[1m203/521\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m38s\u001b[0m 120ms/step - accuracy: 0.7548 - loss: 0.5830Batch 3330: logs={'accuracy': 0.7566252946853638, 'loss': 0.5734882354736328}\n",
      "\u001b[1m213/521\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m36s\u001b[0m 120ms/step - accuracy: 0.7549 - loss: 0.5826Batch 3340: logs={'accuracy': 0.7556220889091492, 'loss': 0.5749655961990356}\n",
      "\u001b[1m223/521\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m35s\u001b[0m 120ms/step - accuracy: 0.7549 - loss: 0.5823Batch 3350: logs={'accuracy': 0.756591796875, 'loss': 0.5726638436317444}\n",
      "\u001b[1m233/521\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m34s\u001b[0m 119ms/step - accuracy: 0.7550 - loss: 0.5819Batch 3360: logs={'accuracy': 0.7563434839248657, 'loss': 0.5734961032867432}\n",
      "\u001b[1m243/521\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m32s\u001b[0m 119ms/step - accuracy: 0.7550 - loss: 0.5815Batch 3370: logs={'accuracy': 0.7569800019264221, 'loss': 0.5728355646133423}\n",
      "\u001b[1m253/521\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m31s\u001b[0m 118ms/step - accuracy: 0.7551 - loss: 0.5812Batch 3380: logs={'accuracy': 0.7567052245140076, 'loss': 0.5737943649291992}\n",
      "\u001b[1m263/521\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m30s\u001b[0m 118ms/step - accuracy: 0.7552 - loss: 0.5809Batch 3390: logs={'accuracy': 0.7581971883773804, 'loss': 0.5719642639160156}\n",
      "\u001b[1m273/521\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m29s\u001b[0m 118ms/step - accuracy: 0.7553 - loss: 0.5806Batch 3400: logs={'accuracy': 0.7582972049713135, 'loss': 0.5717945098876953}\n",
      "\u001b[1m283/521\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m27s\u001b[0m 117ms/step - accuracy: 0.7554 - loss: 0.5802Batch 3410: logs={'accuracy': 0.759105384349823, 'loss': 0.5702386498451233}\n",
      "\u001b[1m293/521\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m26s\u001b[0m 118ms/step - accuracy: 0.7556 - loss: 0.5799Batch 3420: logs={'accuracy': 0.7589817047119141, 'loss': 0.5707331299781799}\n",
      "\u001b[1m303/521\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m25s\u001b[0m 118ms/step - accuracy: 0.7557 - loss: 0.5796Batch 3430: logs={'accuracy': 0.7597399353981018, 'loss': 0.5688545107841492}\n",
      "\u001b[1m313/521\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 118ms/step - accuracy: 0.7558 - loss: 0.5792Batch 3440: logs={'accuracy': 0.7601761817932129, 'loss': 0.568702757358551}\n",
      "\u001b[1m323/521\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 118ms/step - accuracy: 0.7560 - loss: 0.5789Batch 3450: logs={'accuracy': 0.759789764881134, 'loss': 0.5699793696403503}\n",
      "\u001b[1m333/521\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 118ms/step - accuracy: 0.7561 - loss: 0.5786Batch 3460: logs={'accuracy': 0.7601983547210693, 'loss': 0.5691606402397156}\n",
      "\u001b[1m343/521\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 118ms/step - accuracy: 0.7562 - loss: 0.5784Batch 3470: logs={'accuracy': 0.7604242563247681, 'loss': 0.5687733292579651}\n",
      "\u001b[1m353/521\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 119ms/step - accuracy: 0.7563 - loss: 0.5781Batch 3480: logs={'accuracy': 0.7606373429298401, 'loss': 0.5682797431945801}\n",
      "\u001b[1m363/521\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 120ms/step - accuracy: 0.7564 - loss: 0.5778Batch 3490: logs={'accuracy': 0.7605168223381042, 'loss': 0.5691455602645874}\n",
      "\u001b[1m373/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 120ms/step - accuracy: 0.7566 - loss: 0.5776Batch 3500: logs={'accuracy': 0.7604236006736755, 'loss': 0.5693069696426392}\n",
      "\u001b[1m383/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 120ms/step - accuracy: 0.7566 - loss: 0.5774Batch 3510: logs={'accuracy': 0.76055908203125, 'loss': 0.5692984461784363}\n",
      "\u001b[1m393/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 121ms/step - accuracy: 0.7567 - loss: 0.5772Batch 3520: logs={'accuracy': 0.7604893445968628, 'loss': 0.5696310997009277}\n",
      "\u001b[1m403/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m14s\u001b[0m 121ms/step - accuracy: 0.7568 - loss: 0.5770Batch 3530: logs={'accuracy': 0.7604811191558838, 'loss': 0.5697864294052124}\n",
      "\u001b[1m413/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m13s\u001b[0m 121ms/step - accuracy: 0.7569 - loss: 0.5768Batch 3540: logs={'accuracy': 0.7601336240768433, 'loss': 0.5699131488800049}\n",
      "\u001b[1m423/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m11s\u001b[0m 121ms/step - accuracy: 0.7570 - loss: 0.5767Batch 3550: logs={'accuracy': 0.7604289650917053, 'loss': 0.5689959526062012}\n",
      "\u001b[1m433/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m10s\u001b[0m 121ms/step - accuracy: 0.7571 - loss: 0.5765Batch 3560: logs={'accuracy': 0.760188639163971, 'loss': 0.5692282319068909}\n",
      "\u001b[1m443/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m9s\u001b[0m 121ms/step - accuracy: 0.7571 - loss: 0.5763Batch 3570: logs={'accuracy': 0.7602759003639221, 'loss': 0.5688343048095703}\n",
      "\u001b[1m453/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m8s\u001b[0m 121ms/step - accuracy: 0.7572 - loss: 0.5761Batch 3580: logs={'accuracy': 0.760496973991394, 'loss': 0.5682525634765625}\n",
      "\u001b[1m463/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m6s\u001b[0m 120ms/step - accuracy: 0.7573 - loss: 0.5760Batch 3590: logs={'accuracy': 0.7604222893714905, 'loss': 0.5683400630950928}\n",
      "\u001b[1m473/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m5s\u001b[0m 120ms/step - accuracy: 0.7573 - loss: 0.5758Batch 3600: logs={'accuracy': 0.7607463002204895, 'loss': 0.5678049921989441}\n",
      "\u001b[1m483/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m4s\u001b[0m 120ms/step - accuracy: 0.7574 - loss: 0.5756Batch 3610: logs={'accuracy': 0.761073112487793, 'loss': 0.5677325129508972}\n",
      "\u001b[1m493/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m3s\u001b[0m 120ms/step - accuracy: 0.7575 - loss: 0.5755Batch 3620: logs={'accuracy': 0.7611019611358643, 'loss': 0.5676329731941223}\n",
      "\u001b[1m503/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m2s\u001b[0m 119ms/step - accuracy: 0.7576 - loss: 0.5753Batch 3630: logs={'accuracy': 0.7615947127342224, 'loss': 0.5672675967216492}\n",
      "\u001b[1m513/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 0.7577 - loss: 0.5752Batch 3640: logs={'accuracy': 0.7617035508155823, 'loss': 0.5670779347419739}\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 119ms/step - accuracy: 0.7577 - loss: 0.5750\n",
      "Epoch 8/10\n",
      "\u001b[1m  2/521\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m51s\u001b[0m 100ms/step - accuracy: 0.8008 - loss: 0.4932 Batch 3650: logs={'accuracy': 0.78125, 'loss': 0.5209165811538696}\n",
      "\u001b[1m 12/521\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m57s\u001b[0m 113ms/step - accuracy: 0.7792 - loss: 0.5277Batch 3660: logs={'accuracy': 0.7740384340286255, 'loss': 0.5448944568634033}\n",
      "\u001b[1m 22/521\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m55s\u001b[0m 112ms/step - accuracy: 0.7761 - loss: 0.5360Batch 3670: logs={'accuracy': 0.770380437374115, 'loss': 0.5482290387153625}\n",
      "\u001b[1m 32/521\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m54s\u001b[0m 112ms/step - accuracy: 0.7738 - loss: 0.5412Batch 3680: logs={'accuracy': 0.767518937587738, 'loss': 0.5548204183578491}\n",
      "\u001b[1m 42/521\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m53s\u001b[0m 113ms/step - accuracy: 0.7718 - loss: 0.5448Batch 3690: logs={'accuracy': 0.7636264562606812, 'loss': 0.5616134405136108}\n",
      "\u001b[1m 52/521\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m54s\u001b[0m 117ms/step - accuracy: 0.7705 - loss: 0.5473Batch 3700: logs={'accuracy': 0.7666568160057068, 'loss': 0.5532556176185608}\n",
      "\u001b[1m 62/521\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m54s\u001b[0m 118ms/step - accuracy: 0.7696 - loss: 0.5489Batch 3710: logs={'accuracy': 0.7648809552192688, 'loss': 0.5579406023025513}\n",
      "\u001b[1m 72/521\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m53s\u001b[0m 118ms/step - accuracy: 0.7691 - loss: 0.5499Batch 3720: logs={'accuracy': 0.7649828791618347, 'loss': 0.5584861040115356}\n",
      "\u001b[1m 82/521\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m53s\u001b[0m 121ms/step - accuracy: 0.7688 - loss: 0.5507Batch 3730: logs={'accuracy': 0.7676016688346863, 'loss': 0.5552117228507996}\n",
      "\u001b[1m 92/521\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m51s\u001b[0m 121ms/step - accuracy: 0.7686 - loss: 0.5511Batch 3740: logs={'accuracy': 0.7678091526031494, 'loss': 0.5527186989784241}\n",
      "\u001b[1m102/521\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m50s\u001b[0m 121ms/step - accuracy: 0.7687 - loss: 0.5511Batch 3750: logs={'accuracy': 0.7694933414459229, 'loss': 0.5508779287338257}\n",
      "\u001b[1m112/521\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m49s\u001b[0m 122ms/step - accuracy: 0.7687 - loss: 0.5511Batch 3760: logs={'accuracy': 0.7685287594795227, 'loss': 0.5524723529815674}\n",
      "\u001b[1m122/521\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m48s\u001b[0m 122ms/step - accuracy: 0.7687 - loss: 0.5512Batch 3770: logs={'accuracy': 0.7689913511276245, 'loss': 0.5507246851921082}\n",
      "\u001b[1m132/521\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m48s\u001b[0m 124ms/step - accuracy: 0.7687 - loss: 0.5513Batch 3780: logs={'accuracy': 0.7680920958518982, 'loss': 0.5530287027359009}\n",
      "\u001b[1m142/521\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m46s\u001b[0m 123ms/step - accuracy: 0.7686 - loss: 0.5514Batch 3790: logs={'accuracy': 0.7671000957489014, 'loss': 0.5546714663505554}\n",
      "\u001b[1m152/521\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m45s\u001b[0m 123ms/step - accuracy: 0.7685 - loss: 0.5517Batch 3800: logs={'accuracy': 0.7671568393707275, 'loss': 0.5549545884132385}\n",
      "\u001b[1m162/521\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m44s\u001b[0m 123ms/step - accuracy: 0.7685 - loss: 0.5518Batch 3810: logs={'accuracy': 0.7689321041107178, 'loss': 0.5529477000236511}\n",
      "\u001b[1m172/521\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m42s\u001b[0m 123ms/step - accuracy: 0.7685 - loss: 0.5518Batch 3820: logs={'accuracy': 0.7688313126564026, 'loss': 0.5517929792404175}\n",
      "\u001b[1m182/521\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m41s\u001b[0m 123ms/step - accuracy: 0.7685 - loss: 0.5519Batch 3830: logs={'accuracy': 0.7683999538421631, 'loss': 0.5532299280166626}\n",
      "\u001b[1m192/521\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m40s\u001b[0m 124ms/step - accuracy: 0.7685 - loss: 0.5519Batch 3840: logs={'accuracy': 0.7679322957992554, 'loss': 0.5526076555252075}\n",
      "\u001b[1m202/521\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m39s\u001b[0m 124ms/step - accuracy: 0.7685 - loss: 0.5520Batch 3850: logs={'accuracy': 0.7679340839385986, 'loss': 0.5527061223983765}\n",
      "\u001b[1m212/521\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m37s\u001b[0m 123ms/step - accuracy: 0.7684 - loss: 0.5520Batch 3860: logs={'accuracy': 0.7666886448860168, 'loss': 0.553753137588501}\n",
      "\u001b[1m222/521\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m36s\u001b[0m 122ms/step - accuracy: 0.7683 - loss: 0.5521Batch 3870: logs={'accuracy': 0.7666059136390686, 'loss': 0.5539872646331787}\n",
      "\u001b[1m232/521\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m35s\u001b[0m 121ms/step - accuracy: 0.7683 - loss: 0.5521Batch 3880: logs={'accuracy': 0.7671338319778442, 'loss': 0.5538176894187927}\n",
      "\u001b[1m242/521\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m33s\u001b[0m 121ms/step - accuracy: 0.7682 - loss: 0.5522Batch 3890: logs={'accuracy': 0.7661715745925903, 'loss': 0.5555589199066162}\n",
      "\u001b[1m252/521\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m32s\u001b[0m 121ms/step - accuracy: 0.7681 - loss: 0.5523Batch 3900: logs={'accuracy': 0.7664896249771118, 'loss': 0.555708110332489}\n",
      "\u001b[1m262/521\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m31s\u001b[0m 121ms/step - accuracy: 0.7681 - loss: 0.5525Batch 3910: logs={'accuracy': 0.7665755748748779, 'loss': 0.5555311441421509}\n",
      "\u001b[1m272/521\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m30s\u001b[0m 121ms/step - accuracy: 0.7680 - loss: 0.5526Batch 3920: logs={'accuracy': 0.7673420310020447, 'loss': 0.5552358031272888}\n",
      "\u001b[1m282/521\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m28s\u001b[0m 121ms/step - accuracy: 0.7680 - loss: 0.5527Batch 3930: logs={'accuracy': 0.7672261595726013, 'loss': 0.5552399754524231}\n",
      "\u001b[1m292/521\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m27s\u001b[0m 120ms/step - accuracy: 0.7680 - loss: 0.5528Batch 3940: logs={'accuracy': 0.7674914598464966, 'loss': 0.5548317432403564}\n",
      "\u001b[1m302/521\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m26s\u001b[0m 121ms/step - accuracy: 0.7680 - loss: 0.5528Batch 3950: logs={'accuracy': 0.7673782706260681, 'loss': 0.5541250109672546}\n",
      "\u001b[1m312/521\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m25s\u001b[0m 121ms/step - accuracy: 0.7680 - loss: 0.5529Batch 3960: logs={'accuracy': 0.7672973275184631, 'loss': 0.554475724697113}\n",
      "\u001b[1m322/521\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 121ms/step - accuracy: 0.7679 - loss: 0.5529Batch 3970: logs={'accuracy': 0.7678986191749573, 'loss': 0.5540849566459656}\n",
      "\u001b[1m332/521\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 121ms/step - accuracy: 0.7679 - loss: 0.5530Batch 3980: logs={'accuracy': 0.7679945826530457, 'loss': 0.5544446110725403}\n",
      "\u001b[1m342/521\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 122ms/step - accuracy: 0.7679 - loss: 0.5530Batch 3990: logs={'accuracy': 0.767902672290802, 'loss': 0.5545639991760254}\n",
      "\u001b[1m352/521\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 122ms/step - accuracy: 0.7679 - loss: 0.5530Batch 4000: logs={'accuracy': 0.767616868019104, 'loss': 0.5544065833091736}\n",
      "\u001b[1m362/521\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 122ms/step - accuracy: 0.7679 - loss: 0.5531Batch 4010: logs={'accuracy': 0.7677556872367859, 'loss': 0.5544942021369934}\n",
      "\u001b[1m372/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 122ms/step - accuracy: 0.7679 - loss: 0.5531Batch 4020: logs={'accuracy': 0.7677404284477234, 'loss': 0.554684042930603}\n",
      "\u001b[1m382/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 121ms/step - accuracy: 0.7679 - loss: 0.5532Batch 4030: logs={'accuracy': 0.7676036357879639, 'loss': 0.5547731518745422}\n",
      "\u001b[1m392/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 121ms/step - accuracy: 0.7679 - loss: 0.5532Batch 4040: logs={'accuracy': 0.767652690410614, 'loss': 0.5543555617332458}\n",
      "\u001b[1m402/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m14s\u001b[0m 121ms/step - accuracy: 0.7679 - loss: 0.5532Batch 4050: logs={'accuracy': 0.7673115730285645, 'loss': 0.5545559525489807}\n",
      "\u001b[1m412/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m13s\u001b[0m 121ms/step - accuracy: 0.7679 - loss: 0.5533Batch 4060: logs={'accuracy': 0.7670626640319824, 'loss': 0.555086076259613}\n",
      "\u001b[1m422/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m12s\u001b[0m 121ms/step - accuracy: 0.7679 - loss: 0.5533Batch 4070: logs={'accuracy': 0.7670286893844604, 'loss': 0.55509352684021}\n",
      "\u001b[1m432/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m10s\u001b[0m 122ms/step - accuracy: 0.7678 - loss: 0.5534Batch 4080: logs={'accuracy': 0.7669962644577026, 'loss': 0.555178165435791}\n",
      "\u001b[1m442/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m9s\u001b[0m 122ms/step - accuracy: 0.7678 - loss: 0.5534Batch 4090: logs={'accuracy': 0.7674238085746765, 'loss': 0.5551033020019531}\n",
      "\u001b[1m452/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m8s\u001b[0m 122ms/step - accuracy: 0.7678 - loss: 0.5534Batch 4100: logs={'accuracy': 0.767194390296936, 'loss': 0.5553485751152039}\n",
      "\u001b[1m462/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m7s\u001b[0m 122ms/step - accuracy: 0.7678 - loss: 0.5535Batch 4110: logs={'accuracy': 0.767126739025116, 'loss': 0.5554618239402771}\n",
      "\u001b[1m472/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m5s\u001b[0m 122ms/step - accuracy: 0.7678 - loss: 0.5535Batch 4120: logs={'accuracy': 0.7675409913063049, 'loss': 0.5542314052581787}\n",
      "\u001b[1m482/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m4s\u001b[0m 123ms/step - accuracy: 0.7678 - loss: 0.5535Batch 4130: logs={'accuracy': 0.7677762508392334, 'loss': 0.554103434085846}\n",
      "\u001b[1m492/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m3s\u001b[0m 123ms/step - accuracy: 0.7678 - loss: 0.5536Batch 4140: logs={'accuracy': 0.7677801847457886, 'loss': 0.5543813109397888}\n",
      "\u001b[1m502/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m2s\u001b[0m 122ms/step - accuracy: 0.7678 - loss: 0.5536Batch 4150: logs={'accuracy': 0.7678926587104797, 'loss': 0.5544640421867371}\n",
      "\u001b[1m512/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - accuracy: 0.7678 - loss: 0.5536Batch 4160: logs={'accuracy': 0.7680311799049377, 'loss': 0.554096519947052}\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - accuracy: 0.7678 - loss: 0.5536Model weights saved for epoch 8\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 123ms/step - accuracy: 0.7678 - loss: 0.5536\n",
      "Epoch 9/10\n",
      "\u001b[1m  1/521\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:21\u001b[0m 156ms/step - accuracy: 0.7969 - loss: 0.4722Batch 4170: logs={'accuracy': 0.7890625, 'loss': 0.5190037488937378}\n",
      "\u001b[1m 11/521\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:00\u001b[0m 118ms/step - accuracy: 0.7971 - loss: 0.5002Batch 4180: logs={'accuracy': 0.7936198115348816, 'loss': 0.5061862468719482}\n",
      "\u001b[1m 21/521\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:01\u001b[0m 123ms/step - accuracy: 0.7935 - loss: 0.5063Batch 4190: logs={'accuracy': 0.7862215638160706, 'loss': 0.5205335021018982}\n",
      "\u001b[1m 31/521\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m58s\u001b[0m 119ms/step - accuracy: 0.7910 - loss: 0.5110Batch 4200: logs={'accuracy': 0.78662109375, 'loss': 0.5209192633628845}\n",
      "\u001b[1m 41/521\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m58s\u001b[0m 122ms/step - accuracy: 0.7901 - loss: 0.5132Batch 4210: logs={'accuracy': 0.7844122052192688, 'loss': 0.5239992737770081}\n",
      "\u001b[1m 51/521\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:00\u001b[0m 128ms/step - accuracy: 0.7888 - loss: 0.5160Batch 4220: logs={'accuracy': 0.7830528616905212, 'loss': 0.5294725894927979}\n",
      "\u001b[1m 61/521\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m58s\u001b[0m 128ms/step - accuracy: 0.7878 - loss: 0.5181Batch 4230: logs={'accuracy': 0.7815020084381104, 'loss': 0.53241366147995}\n",
      "\u001b[1m 71/521\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m58s\u001b[0m 131ms/step - accuracy: 0.7870 - loss: 0.5200Batch 4240: logs={'accuracy': 0.7825520634651184, 'loss': 0.5306817293167114}\n",
      "\u001b[1m 81/521\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m59s\u001b[0m 136ms/step - accuracy: 0.7863 - loss: 0.5216Batch 4250: logs={'accuracy': 0.7803925275802612, 'loss': 0.5353730320930481}\n",
      "\u001b[1m 91/521\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:01\u001b[0m 142ms/step - accuracy: 0.7858 - loss: 0.5230Batch 4260: logs={'accuracy': 0.782863438129425, 'loss': 0.5315967798233032}\n",
      "\u001b[1m101/521\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:01\u001b[0m 146ms/step - accuracy: 0.7853 - loss: 0.5241Batch 4270: logs={'accuracy': 0.7805606722831726, 'loss': 0.5365102291107178}\n",
      "\u001b[1m111/521\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:01\u001b[0m 150ms/step - accuracy: 0.7849 - loss: 0.5252Batch 4280: logs={'accuracy': 0.7813197374343872, 'loss': 0.5354934930801392}\n",
      "\u001b[1m121/521\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:00\u001b[0m 151ms/step - accuracy: 0.7845 - loss: 0.5262Batch 4290: logs={'accuracy': 0.7797771692276001, 'loss': 0.5378352403640747}\n",
      "\u001b[1m131/521\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m58s\u001b[0m 151ms/step - accuracy: 0.7842 - loss: 0.5271Batch 4300: logs={'accuracy': 0.7801846861839294, 'loss': 0.5385074615478516}\n",
      "\u001b[1m141/521\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m57s\u001b[0m 152ms/step - accuracy: 0.7839 - loss: 0.5279Batch 4310: logs={'accuracy': 0.7799845933914185, 'loss': 0.5392469763755798}\n",
      "\u001b[1m151/521\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m56s\u001b[0m 152ms/step - accuracy: 0.7836 - loss: 0.5287Batch 4320: logs={'accuracy': 0.7788342833518982, 'loss': 0.5391611456871033}\n",
      "\u001b[1m161/521\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m54s\u001b[0m 150ms/step - accuracy: 0.7833 - loss: 0.5294Batch 4330: logs={'accuracy': 0.7779706716537476, 'loss': 0.5398908257484436}\n",
      "\u001b[1m171/521\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m51s\u001b[0m 148ms/step - accuracy: 0.7829 - loss: 0.5300Batch 4340: logs={'accuracy': 0.7776162624359131, 'loss': 0.5401985049247742}\n",
      "\u001b[1m181/521\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m49s\u001b[0m 146ms/step - accuracy: 0.7826 - loss: 0.5306Batch 4350: logs={'accuracy': 0.7760559916496277, 'loss': 0.5409197807312012}\n",
      "\u001b[1m191/521\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m47s\u001b[0m 145ms/step - accuracy: 0.7823 - loss: 0.5311Batch 4360: logs={'accuracy': 0.7761637568473816, 'loss': 0.5411200523376465}\n",
      "\u001b[1m201/521\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m46s\u001b[0m 145ms/step - accuracy: 0.7820 - loss: 0.5316Batch 4370: logs={'accuracy': 0.7765315771102905, 'loss': 0.540191113948822}\n",
      "\u001b[1m211/521\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m44s\u001b[0m 144ms/step - accuracy: 0.7817 - loss: 0.5320Batch 4380: logs={'accuracy': 0.7766804099082947, 'loss': 0.5403084754943848}\n",
      "\u001b[1m221/521\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m43s\u001b[0m 144ms/step - accuracy: 0.7815 - loss: 0.5324Batch 4390: logs={'accuracy': 0.776252806186676, 'loss': 0.5411875247955322}\n",
      "\u001b[1m231/521\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m41s\u001b[0m 143ms/step - accuracy: 0.7812 - loss: 0.5328Batch 4400: logs={'accuracy': 0.7758284211158752, 'loss': 0.5415240526199341}\n",
      "\u001b[1m241/521\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m39s\u001b[0m 142ms/step - accuracy: 0.7810 - loss: 0.5331Batch 4410: logs={'accuracy': 0.7749547958374023, 'loss': 0.5419297814369202}\n",
      "\u001b[1m251/521\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m38s\u001b[0m 141ms/step - accuracy: 0.7808 - loss: 0.5335Batch 4420: logs={'accuracy': 0.7746155858039856, 'loss': 0.542180061340332}\n",
      "\u001b[1m261/521\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m36s\u001b[0m 140ms/step - accuracy: 0.7805 - loss: 0.5339Batch 4430: logs={'accuracy': 0.7737357020378113, 'loss': 0.5429657697677612}\n",
      "\u001b[1m271/521\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m34s\u001b[0m 139ms/step - accuracy: 0.7803 - loss: 0.5342Batch 4440: logs={'accuracy': 0.7743566036224365, 'loss': 0.541700541973114}\n",
      "\u001b[1m281/521\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m33s\u001b[0m 138ms/step - accuracy: 0.7801 - loss: 0.5344Batch 4450: logs={'accuracy': 0.7747119069099426, 'loss': 0.5410864949226379}\n",
      "\u001b[1m291/521\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m31s\u001b[0m 137ms/step - accuracy: 0.7799 - loss: 0.5347Batch 4460: logs={'accuracy': 0.7745879888534546, 'loss': 0.5409297347068787}\n",
      "\u001b[1m301/521\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m29s\u001b[0m 136ms/step - accuracy: 0.7797 - loss: 0.5349Batch 4470: logs={'accuracy': 0.7755070328712463, 'loss': 0.5395462512969971}\n",
      "\u001b[1m311/521\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m28s\u001b[0m 135ms/step - accuracy: 0.7796 - loss: 0.5350Batch 4480: logs={'accuracy': 0.7757411599159241, 'loss': 0.5393644571304321}\n",
      "\u001b[1m321/521\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m26s\u001b[0m 134ms/step - accuracy: 0.7795 - loss: 0.5351Batch 4490: logs={'accuracy': 0.7759365439414978, 'loss': 0.5392806529998779}\n",
      "\u001b[1m331/521\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m25s\u001b[0m 134ms/step - accuracy: 0.7794 - loss: 0.5353Batch 4500: logs={'accuracy': 0.7762848138809204, 'loss': 0.5381467938423157}\n",
      "\u001b[1m341/521\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 133ms/step - accuracy: 0.7793 - loss: 0.5353Batch 4510: logs={'accuracy': 0.7759731411933899, 'loss': 0.5383318066596985}\n",
      "\u001b[1m351/521\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 133ms/step - accuracy: 0.7792 - loss: 0.5354Batch 4520: logs={'accuracy': 0.77587890625, 'loss': 0.5383508801460266}\n",
      "\u001b[1m361/521\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 133ms/step - accuracy: 0.7791 - loss: 0.5355Batch 4530: logs={'accuracy': 0.7759193778038025, 'loss': 0.5384430885314941}\n",
      "\u001b[1m371/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 133ms/step - accuracy: 0.7790 - loss: 0.5356Batch 4540: logs={'accuracy': 0.7759996652603149, 'loss': 0.5386033058166504}\n",
      "\u001b[1m381/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 133ms/step - accuracy: 0.7789 - loss: 0.5357Batch 4550: logs={'accuracy': 0.7757485508918762, 'loss': 0.538486123085022}\n",
      "\u001b[1m391/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m17s\u001b[0m 132ms/step - accuracy: 0.7788 - loss: 0.5357Batch 4560: logs={'accuracy': 0.7756297588348389, 'loss': 0.5388994216918945}\n",
      "\u001b[1m401/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 131ms/step - accuracy: 0.7788 - loss: 0.5358Batch 4570: logs={'accuracy': 0.7758084535598755, 'loss': 0.5386587381362915}\n",
      "\u001b[1m411/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m14s\u001b[0m 131ms/step - accuracy: 0.7787 - loss: 0.5359Batch 4580: logs={'accuracy': 0.7758646607398987, 'loss': 0.5385997295379639}\n",
      "\u001b[1m421/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m13s\u001b[0m 131ms/step - accuracy: 0.7786 - loss: 0.5360Batch 4590: logs={'accuracy': 0.7764366269111633, 'loss': 0.5376962423324585}\n",
      "\u001b[1m431/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m11s\u001b[0m 131ms/step - accuracy: 0.7786 - loss: 0.5360Batch 4600: logs={'accuracy': 0.7762587070465088, 'loss': 0.5373822450637817}\n",
      "\u001b[1m441/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m10s\u001b[0m 130ms/step - accuracy: 0.7785 - loss: 0.5360Batch 4610: logs={'accuracy': 0.7763009071350098, 'loss': 0.5373800992965698}\n",
      "\u001b[1m451/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m9s\u001b[0m 130ms/step - accuracy: 0.7785 - loss: 0.5361Batch 4620: logs={'accuracy': 0.7766178250312805, 'loss': 0.5371861457824707}\n",
      "\u001b[1m461/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m7s\u001b[0m 130ms/step - accuracy: 0.7784 - loss: 0.5361Batch 4630: logs={'accuracy': 0.7769041061401367, 'loss': 0.5368909239768982}\n",
      "\u001b[1m471/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m6s\u001b[0m 130ms/step - accuracy: 0.7784 - loss: 0.5361Batch 4640: logs={'accuracy': 0.7765823602676392, 'loss': 0.5373924970626831}\n",
      "\u001b[1m481/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m5s\u001b[0m 130ms/step - accuracy: 0.7784 - loss: 0.5361Batch 4650: logs={'accuracy': 0.7766792178153992, 'loss': 0.5370396375656128}\n",
      "\u001b[1m491/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - accuracy: 0.7783 - loss: 0.5362Batch 4660: logs={'accuracy': 0.7768038511276245, 'loss': 0.5376455187797546}\n",
      "\u001b[1m501/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m2s\u001b[0m 130ms/step - accuracy: 0.7783 - loss: 0.5362Batch 4670: logs={'accuracy': 0.7765656113624573, 'loss': 0.5384988784790039}\n",
      "\u001b[1m511/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - accuracy: 0.7783 - loss: 0.5362Batch 4680: logs={'accuracy': 0.7764739990234375, 'loss': 0.5386642813682556}\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 130ms/step - accuracy: 0.7782 - loss: 0.5363\n",
      "Epoch 10/10\n",
      "Batch 4690: logs={'accuracy': 0.7890625, 'loss': 0.5333470106124878}\n",
      "\u001b[1m 10/521\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:06\u001b[0m 131ms/step - accuracy: 0.7878 - loss: 0.5208Batch 4700: logs={'accuracy': 0.7776988744735718, 'loss': 0.5481167435646057}\n",
      "\u001b[1m 20/521\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:08\u001b[0m 136ms/step - accuracy: 0.7837 - loss: 0.5307Batch 4710: logs={'accuracy': 0.7764136791229248, 'loss': 0.5371165871620178}\n",
      "\u001b[1m 30/521\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:09\u001b[0m 141ms/step - accuracy: 0.7812 - loss: 0.5327Batch 4720: logs={'accuracy': 0.7772177457809448, 'loss': 0.5369592308998108}\n",
      "\u001b[1m 40/521\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:07\u001b[0m 140ms/step - accuracy: 0.7799 - loss: 0.5344Batch 4730: logs={'accuracy': 0.7751524448394775, 'loss': 0.5414745211601257}\n",
      "\u001b[1m 50/521\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:04\u001b[0m 137ms/step - accuracy: 0.7791 - loss: 0.5351Batch 4740: logs={'accuracy': 0.7772671580314636, 'loss': 0.5354886054992676}\n",
      "\u001b[1m 60/521\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:02\u001b[0m 135ms/step - accuracy: 0.7786 - loss: 0.5354Batch 4750: logs={'accuracy': 0.7757428288459778, 'loss': 0.5377737283706665}\n",
      "\u001b[1m 70/521\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:00\u001b[0m 134ms/step - accuracy: 0.7785 - loss: 0.5353Batch 4760: logs={'accuracy': 0.7780590057373047, 'loss': 0.534917950630188}\n",
      "\u001b[1m 80/521\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m58s\u001b[0m 132ms/step - accuracy: 0.7786 - loss: 0.5350Batch 4770: logs={'accuracy': 0.7795138955116272, 'loss': 0.5326188802719116}\n",
      "\u001b[1m 90/521\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m56s\u001b[0m 131ms/step - accuracy: 0.7788 - loss: 0.5346Batch 4780: logs={'accuracy': 0.7820226550102234, 'loss': 0.5293921828269958}\n",
      "\u001b[1m100/521\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m54s\u001b[0m 130ms/step - accuracy: 0.7791 - loss: 0.5341Batch 4790: logs={'accuracy': 0.7819461822509766, 'loss': 0.5294756293296814}\n",
      "\u001b[1m110/521\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m53s\u001b[0m 130ms/step - accuracy: 0.7793 - loss: 0.5337Batch 4800: logs={'accuracy': 0.7799831032752991, 'loss': 0.5310048460960388}\n",
      "\u001b[1m120/521\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m51s\u001b[0m 129ms/step - accuracy: 0.7793 - loss: 0.5335Batch 4810: logs={'accuracy': 0.7789255976676941, 'loss': 0.5320234894752502}\n",
      "\u001b[1m130/521\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m49s\u001b[0m 128ms/step - accuracy: 0.7793 - loss: 0.5334Batch 4820: logs={'accuracy': 0.7787452340126038, 'loss': 0.533166229724884}\n",
      "\u001b[1m140/521\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m48s\u001b[0m 127ms/step - accuracy: 0.7793 - loss: 0.5333Batch 4830: logs={'accuracy': 0.7793107032775879, 'loss': 0.5328986644744873}\n",
      "\u001b[1m150/521\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m47s\u001b[0m 129ms/step - accuracy: 0.7793 - loss: 0.5333Batch 4840: logs={'accuracy': 0.7800599932670593, 'loss': 0.5315771698951721}\n",
      "\u001b[1m160/521\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m48s\u001b[0m 134ms/step - accuracy: 0.7794 - loss: 0.5332Batch 4850: logs={'accuracy': 0.7796001434326172, 'loss': 0.5330365300178528}\n",
      "\u001b[1m170/521\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m49s\u001b[0m 140ms/step - accuracy: 0.7794 - loss: 0.5331Batch 4860: logs={'accuracy': 0.7800621390342712, 'loss': 0.532348096370697}\n",
      "\u001b[1m180/521\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m48s\u001b[0m 142ms/step - accuracy: 0.7794 - loss: 0.5331Batch 4870: logs={'accuracy': 0.7801709175109863, 'loss': 0.5319665670394897}\n",
      "\u001b[1m190/521\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m46s\u001b[0m 141ms/step - accuracy: 0.7795 - loss: 0.5330Batch 4880: logs={'accuracy': 0.7802683115005493, 'loss': 0.5304948687553406}\n",
      "\u001b[1m200/521\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m44s\u001b[0m 140ms/step - accuracy: 0.7795 - loss: 0.5329Batch 4890: logs={'accuracy': 0.7796564102172852, 'loss': 0.5309692025184631}\n",
      "\u001b[1m210/521\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m43s\u001b[0m 139ms/step - accuracy: 0.7795 - loss: 0.5328Batch 4900: logs={'accuracy': 0.7789543867111206, 'loss': 0.5324820876121521}\n",
      "\u001b[1m220/521\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m41s\u001b[0m 138ms/step - accuracy: 0.7795 - loss: 0.5328Batch 4910: logs={'accuracy': 0.7787047624588013, 'loss': 0.5323866605758667}\n",
      "\u001b[1m230/521\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m40s\u001b[0m 138ms/step - accuracy: 0.7794 - loss: 0.5328Batch 4920: logs={'accuracy': 0.7791531682014465, 'loss': 0.5310848355293274}\n",
      "\u001b[1m240/521\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m38s\u001b[0m 137ms/step - accuracy: 0.7794 - loss: 0.5327Batch 4930: logs={'accuracy': 0.7799533009529114, 'loss': 0.5304100513458252}\n",
      "\u001b[1m250/521\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m37s\u001b[0m 138ms/step - accuracy: 0.7795 - loss: 0.5326Batch 4940: logs={'accuracy': 0.7805963754653931, 'loss': 0.5296455025672913}\n",
      "\u001b[1m260/521\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m35s\u001b[0m 138ms/step - accuracy: 0.7795 - loss: 0.5325Batch 4950: logs={'accuracy': 0.780501663684845, 'loss': 0.5296677350997925}\n",
      "\u001b[1m270/521\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m34s\u001b[0m 138ms/step - accuracy: 0.7796 - loss: 0.5323Batch 4960: logs={'accuracy': 0.7807310819625854, 'loss': 0.5291556119918823}\n",
      "\u001b[1m280/521\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m33s\u001b[0m 138ms/step - accuracy: 0.7796 - loss: 0.5322Batch 4970: logs={'accuracy': 0.7807495594024658, 'loss': 0.5289340019226074}\n",
      "\u001b[1m290/521\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m31s\u001b[0m 138ms/step - accuracy: 0.7796 - loss: 0.5321Batch 4980: logs={'accuracy': 0.7804177403450012, 'loss': 0.5291394591331482}\n",
      "\u001b[1m300/521\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m30s\u001b[0m 138ms/step - accuracy: 0.7797 - loss: 0.5320Batch 4990: logs={'accuracy': 0.7797965407371521, 'loss': 0.5303431153297424}\n",
      "\u001b[1m310/521\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m29s\u001b[0m 139ms/step - accuracy: 0.7797 - loss: 0.5320Batch 5000: logs={'accuracy': 0.7792403697967529, 'loss': 0.5312238335609436}\n",
      "\u001b[1m320/521\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m28s\u001b[0m 140ms/step - accuracy: 0.7796 - loss: 0.5319Batch 5010: logs={'accuracy': 0.779132604598999, 'loss': 0.5313546061515808}\n",
      "\u001b[1m330/521\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m26s\u001b[0m 139ms/step - accuracy: 0.7796 - loss: 0.5319Batch 5020: logs={'accuracy': 0.7793853878974915, 'loss': 0.5313990712165833}\n",
      "\u001b[1m340/521\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m25s\u001b[0m 138ms/step - accuracy: 0.7796 - loss: 0.5319Batch 5030: logs={'accuracy': 0.7797837257385254, 'loss': 0.5313782691955566}\n",
      "\u001b[1m350/521\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 137ms/step - accuracy: 0.7796 - loss: 0.5319Batch 5040: logs={'accuracy': 0.7801148295402527, 'loss': 0.5304750800132751}\n",
      "\u001b[1m360/521\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 137ms/step - accuracy: 0.7797 - loss: 0.5318Batch 5050: logs={'accuracy': 0.780232846736908, 'loss': 0.5301281809806824}\n",
      "\u001b[1m370/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 136ms/step - accuracy: 0.7797 - loss: 0.5318Batch 5060: logs={'accuracy': 0.7803234457969666, 'loss': 0.5298518538475037}\n",
      "\u001b[1m380/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 136ms/step - accuracy: 0.7797 - loss: 0.5317Batch 5070: logs={'accuracy': 0.7803887724876404, 'loss': 0.5292404890060425}\n",
      "\u001b[1m390/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 135ms/step - accuracy: 0.7797 - loss: 0.5317Batch 5080: logs={'accuracy': 0.7801311016082764, 'loss': 0.5293179750442505}\n",
      "\u001b[1m400/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m16s\u001b[0m 135ms/step - accuracy: 0.7797 - loss: 0.5316Batch 5090: logs={'accuracy': 0.7803537845611572, 'loss': 0.528635561466217}\n",
      "\u001b[1m410/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m14s\u001b[0m 134ms/step - accuracy: 0.7797 - loss: 0.5315Batch 5100: logs={'accuracy': 0.7810028791427612, 'loss': 0.5281554460525513}\n",
      "\u001b[1m420/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m13s\u001b[0m 134ms/step - accuracy: 0.7798 - loss: 0.5314Batch 5110: logs={'accuracy': 0.7812128663063049, 'loss': 0.5276519656181335}\n",
      "\u001b[1m430/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m12s\u001b[0m 134ms/step - accuracy: 0.7798 - loss: 0.5313Batch 5120: logs={'accuracy': 0.7809780836105347, 'loss': 0.528160035610199}\n",
      "\u001b[1m440/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m10s\u001b[0m 133ms/step - accuracy: 0.7798 - loss: 0.5313Batch 5130: logs={'accuracy': 0.7816574573516846, 'loss': 0.5269123911857605}\n",
      "\u001b[1m450/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m9s\u001b[0m 133ms/step - accuracy: 0.7799 - loss: 0.5312Batch 5140: logs={'accuracy': 0.7817003726959229, 'loss': 0.5267354846000671}\n",
      "\u001b[1m460/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m8s\u001b[0m 133ms/step - accuracy: 0.7799 - loss: 0.5311Batch 5150: logs={'accuracy': 0.7817414402961731, 'loss': 0.5267897248268127}\n",
      "\u001b[1m470/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m6s\u001b[0m 133ms/step - accuracy: 0.7800 - loss: 0.5310Batch 5160: logs={'accuracy': 0.7819466590881348, 'loss': 0.5268843173980713}\n",
      "\u001b[1m480/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m5s\u001b[0m 133ms/step - accuracy: 0.7800 - loss: 0.5309Batch 5170: logs={'accuracy': 0.7819971442222595, 'loss': 0.5272724032402039}\n",
      "\u001b[1m490/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m4s\u001b[0m 133ms/step - accuracy: 0.7800 - loss: 0.5308Batch 5180: logs={'accuracy': 0.7819978594779968, 'loss': 0.5275833010673523}\n",
      "\u001b[1m500/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m2s\u001b[0m 134ms/step - accuracy: 0.7801 - loss: 0.5308Batch 5190: logs={'accuracy': 0.7821232676506042, 'loss': 0.5277108550071716}\n",
      "\u001b[1m510/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - accuracy: 0.7801 - loss: 0.5307Batch 5200: logs={'accuracy': 0.7818309664726257, 'loss': 0.5283545255661011}\n",
      "\u001b[1m520/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.7802 - loss: 0.5307Batch 5210: logs={'accuracy': 0.7814262509346008, 'loss': 0.5289955735206604}\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.7802 - loss: 0.5307Model weights saved for epoch 10\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 136ms/step - accuracy: 0.7802 - loss: 0.5307\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1c501765850>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, epochs=10, batch_size=128, callbacks=[batch_callback, epoch_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step\n",
      "Accuracy: 0.5663026521060842, Precision: 0.6355673531583363, Recall: 0.5663026521060842, F1 Score: 0.5164191257756707\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(Y_test, axis=1)\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred_classes)\n",
    "precision = precision_score(y_true, y_pred_classes, average='weighted')\n",
    "recall = recall_score(y_true, y_pred_classes, average='weighted')\n",
    "f1 = f1_score(y_true, y_pred_classes, average='weighted')\n",
    "\n",
    "print(f\"Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, F1 Score: {f1}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "facedetect",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
